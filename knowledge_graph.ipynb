{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"output2.txt\"\n",
    "output_dir = Path(f\"./output_dir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 10\n",
      "Cdb = AllocateZeroPool (EFI_SCSI_OP_LENGTH_SIXTEEN);\n",
      "  if (Cdb == NULL) {\n",
      "    Status = EFI_OUT_OF_RESOURCES;\n",
      "    goto ErrorExit;\n",
      "  }\n",
      "\n",
      "  Context->SenseDataLength   = SenseDataLength;\n",
      "  Context->HostAdapterStatus = HostAdapterStatus;\n",
      "  Context->TargetStatus      = TargetStatus;\n",
      "  Context->CallerEvent       = Event;\n",
      "\n",
      "  CommandPacket                   = &Context->CommandPacket;\n",
      "  CommandPacket->Timeout          = Timeout;\n",
      "  CommandPacket->InDataBuffer     = DataBuffer;\n",
      "  CommandPacket->SenseData        = SenseData;\n",
      "  CommandPacket->InTransferLength = *DataLength;\n",
      "  CommandPacket->Cdb              = Cdb;\n",
      "  //\n",
      "  // Fill Cdb for Read (16) Command\n",
      "  //\n",
      "  Cdb[0] = EFI_SCSI_OP_READ16;\n",
      "  WriteUnaligned64 ((UINT64 *)&Cdb[2], SwapBytes64 (StartLba));\n",
      "  WriteUnaligned32 ((UINT32 *)&Cdb[10], SwapBytes32 (SectorSize));\n",
      "\n",
      "  CommandPacket->CdbLength       = EFI_SCSI_OP_LENGTH_SIXTEEN;\n",
      "  CommandPacket->DataDirection   = EFI_SCSI_DATA_IN;\n",
      "  CommandPacket->SenseDataLength = *SenseDataLength;\n",
      "\n",
      "  //\n",
      "  // Create Event\n",
      "  //\n",
      "  Status = gBS->CreateEvent (\n",
      "                  EVT_NOTIFY_SIGNAL,\n",
      "                  TPL_NOTIFY,\n",
      "                  ScsiLibNotify,\n",
      "                  Context,\n",
      "                  &SelfEvent\n",
      "                  );\n",
      "  if (EFI_ERROR (Status)) {\n",
      "    goto ErrorExit;\n",
      "  }\n",
      "\n",
      "  Status = ScsiIo->ExecuteScsiCommand (ScsiIo, CommandPacket, SelfEvent);\n",
      "  if (EFI_ERROR (Status)) {\n",
      "    //\n",
      "    // Since ScsiLibNotify() will not be signaled if ExecuteScsiCommand()\n",
      "    // returns with error, close the event here.\n",
      "    //\n",
      "    gBS->CloseEvent (SelfEvent);\n",
      "    goto ErrorExit;\n",
      "  } else {\n",
      "    return EFI_SUCCESS;\n",
      "  }\n",
      "\n",
      "ErrorExit:\n",
      "  if (Context != NULL) {\n",
      "    FreePool (Context);\n",
      "  }\n",
      "\n",
      "  return Status;\n",
      "}\n",
      "\n",
      "/**\n",
      "  Execute blocking/non-blocking Write(16) SCSI command on a specific SCSI\n",
      "  target.\n",
      "\n",
      "  Executes the SCSI Write(16) command on the SCSI target specified by ScsiIo.\n",
      "  When Event is NULL, blocking command will be executed. Otherwise non-blocking\n",
      "  command will be executed.\n",
      "  For blocking I/O, if Timeout is zero, this function will wait indefinitely\n",
      "  for the command to complete. If Timeout is greater than zero, then the\n",
      "  command is executed and will timeout after Timeout 100 ns units.\n",
      "  For non-blocking I/O, if Timeout is zero, Event will be signaled only after\n",
      "  the command to completes. If Timeout is greater than zero, Event will also be\n",
      "  signaled after Timeout 100 ns units.\n",
      "  The StartLba and SectorSize parameters are used to construct the CDB for this\n",
      "  SCSI command.\n",
      "\n",
      "  If ScsiIo is NULL, then ASSERT().\n",
      "  If SenseDataLength is NULL, then ASSERT().\n",
      "  If HostAdapterStatus is NULL, then ASSERT().\n",
      "  If TargetStatus is NULL, then ASSERT().\n",
      "  If DataLength is NULL, then ASSERT().\n",
      "\n",
      "  If SenseDataLength is non-zero and SenseData is not NULL, SenseData must meet\n",
      "  buffer alignment requirement defined in EFI_SCSI_IO_PROTOCOL. Otherwise\n",
      "  EFI_INVALID_PARAMETER gets returned.\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(data_file, encoding='utf-8')\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap = 100,\n",
    "    length_function = len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "pages = splitter.split_documents(documents)\n",
    "pages = pages[10000:10010]\n",
    "print(f\"Number of pages: {len(pages)}\")\n",
    "print(pages[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "api_key = os.getenv('API_KEY')\n",
    "base_url = os.getenv('API_URL')\n",
    "max_output_tokens = 300\n",
    "streaming = False\n",
    "http_client = httpx.Client(verify=False)\n",
    "available_models = [\n",
    "    \"mixtral-8x7b-instruct-v01\", \n",
    "    \"gemma-7b-it\", \n",
    "    \"mistral-7b-instruct-v02\", \n",
    "    \"llama-2-70b-chat\", \n",
    "    \"phi-3-mini-128k-instruct\", \n",
    "    \"llama-3-8b-instruct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from yachalk import chalk\n",
    "from langchain_openai import ChatOpenAI,OpenAI\n",
    "\n",
    "# Append the parent directory to the system path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Initialize the ChatOpenAI client\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    model=available_models[5],\n",
    "    http_client=http_client,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "def trim_incomplete_json(json_string):\n",
    "    # Find the last occurrence of '}]' or '},' in the string\n",
    "    last_complete = max(json_string.rfind('}]'), json_string.rfind('},'))\n",
    "    \n",
    "    if last_complete != -1:\n",
    "        # If found, trim the string to that point and add closing bracket if needed\n",
    "        trimmed = json_string[:last_complete+1]\n",
    "        if not trimmed.endswith(']'):\n",
    "            trimmed += ']'\n",
    "        return trimmed\n",
    "    else:\n",
    "        # If no complete object found, return empty list\n",
    "        return '[]'\n",
    "\n",
    "def extract_concepts(prompt: str, metadata: dict = {}) -> list:\n",
    "    SYS_PROMPT = (\n",
    "        \"Your task is to extract the key concepts (and non-personal entities) mentioned in the given context. \"\n",
    "        \"Extract only the most important and atomistic concepts, breaking them down into simpler concepts if needed. \"\n",
    "        \"Categorize the concepts into one of the following categories: \"\n",
    "        \"[import, concept, function, object, document, class, condition, misc].\\n\"\n",
    "        \"Format your output as a list of JSON objects in the following format:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"   {\\n\"\n",
    "        '       \"entity\": \"The Concept\",\\n'\n",
    "        '       \"importance\": \"The contextual importance of the concept on a scale of 1 to 5 (5 being the highest)\",\\n'\n",
    "        '       \"category\": \"The Type of Concept\"\\n'\n",
    "        \"   },\\n\"\n",
    "        \"   {...}\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    response = client.invoke(input=messages)\n",
    "    print(\"Extract Prompt \", response)\n",
    "    try:\n",
    "        result = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"\\n\\nWARNING ### Incomplete JSON detected. Attempting to trim...\")\n",
    "        trimmed_response = trim_incomplete_json(response)\n",
    "        print(trimmed_response+\"\\n#####################################################################################################\")\n",
    "        try:\n",
    "            result = json.loads(trimmed_response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"\\n\\nERROR ### Failed to parse even after trimming. Here is the buggy response: \", response, \"\\n\\n\")\n",
    "            return None\n",
    "\n",
    "    if result is not None:\n",
    "        result = [dict(item, **metadata) for item in result]\n",
    "\n",
    "    return result\n",
    "\n",
    "def graph_prompt(input_text: str, metadata: dict = {}) -> list:\n",
    "    SYS_PROMPT = (\n",
    "        \"You are a network graph maker who extracts terms and their relations from a given context. \"\n",
    "        \"You are provided with a context chunk (delimited by ```). Your task is to extract the ontology \"\n",
    "        \"of terms mentioned in the given context. These terms should represent the key concepts according to the context.\\n\"\n",
    "        \"Thought 1: While traversing through each sentence, think about the key terms mentioned in it.\\n\"\n",
    "        \"\\tTerms may include object, entity, class, import, function, \\n\"\n",
    "        \"\\tcondition, parameters, documents, service, concept, etc.\\n\"\n",
    "        \"\\tTerms should be as atomistic as possible.\\n\\n\"\n",
    "        \"Thought 2: Think about how these terms can have one-on-one relations with other terms.\\n\"\n",
    "        \"\\tTerms mentioned in the same code or file are typically related to each other.\\n\"\n",
    "        \"\\tTerms can be related to many other terms.\\n\\n\"\n",
    "        \"Thought 3: Determine the relation between each related pair of terms.\\n\\n\"\n",
    "        \"Format your output as a list of JSON objects. Each element of the list contains a pair of terms do not provide an explanation, JUST THE JSON OUTPUT \"\n",
    "        \"and the relationship between them, as follows:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"   {\\n\"\n",
    "        '       \"node_1\": \"A concept from the extracted ontology\",\\n'\n",
    "        '       \"node_2\": \"A related concept from the extracted ontology\",\\n'\n",
    "        '       \"edge\": \"The relationship between node_1 and node_2 in one or two sentences\"\\n'\n",
    "        \"   },\\n\"\n",
    "        \"   {...}\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "\n",
    "    USER_PROMPT = f\"context: ```{input_text}``` \\n\\n output: \"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT}\n",
    "    ]\n",
    "\n",
    "    response = client.invoke(input=messages)\n",
    "    # print(\"Graph Prompt \", response)\n",
    "    try:\n",
    "        result = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        # print(\"\\n\\nWARNING ### Incomplete JSON detected. Attempting to trim...\")\n",
    "        trimmed_response = trim_incomplete_json(response)\n",
    "        # print(trimmed_response)\n",
    "        # print(\"################################################################################################################\")\n",
    "        try:\n",
    "            result = json.loads(trimmed_response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"\\n\\nERROR ### Failed to parse even after trimming. Here is the buggy response: \")\n",
    "            return None\n",
    "\n",
    "    if result is not None:\n",
    "        result = [dict(item, **metadata) for item in result]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def documents2Dataframe(documents) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for chunk in documents:\n",
    "        row = {\n",
    "            \"text\": chunk.page_content,\n",
    "            **chunk.metadata,\n",
    "            \"chunk_id\": uuid.uuid4().hex,\n",
    "        }\n",
    "        rows = rows + [row]\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df2ConceptsList(dataframe: pd.DataFrame) -> list:\n",
    "    # dataframe.reset_index(inplace=True)\n",
    "    results = dataframe.apply(\n",
    "        lambda row: extract_concepts(\n",
    "            row.text, {\"chunk_id\": row.chunk_id, \"type\": \"concept\"}\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    # invalid json results in NaN\n",
    "    results = results.dropna()\n",
    "    results = results.reset_index(drop=True)\n",
    "\n",
    "    ## Flatten the list of lists to one single list of entities.\n",
    "    concept_list = np.concatenate(results).ravel().tolist()\n",
    "    return concept_list\n",
    "\n",
    "\n",
    "def concepts2Df(concepts_list) -> pd.DataFrame:\n",
    "    ## Remove all NaN entities\n",
    "    concepts_dataframe = pd.DataFrame(concepts_list).replace(\" \", np.nan)\n",
    "    concepts_dataframe = concepts_dataframe.dropna(subset=[\"entity\"])\n",
    "    concepts_dataframe[\"entity\"] = concepts_dataframe[\"entity\"].apply(\n",
    "        lambda x: x.lower()\n",
    "    )\n",
    "\n",
    "    return concepts_dataframe\n",
    "\n",
    "\n",
    "def df2Graph(dataframe: pd.DataFrame, model=None) -> list:\n",
    "    total_rows = len(dataframe)\n",
    "    processed_rows = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    def process_row(row):\n",
    "        nonlocal processed_rows\n",
    "        result = graph_prompt(row.text, {\"chunk_id\": row.chunk_id})\n",
    "        processed_rows += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        avg_time_per_row = elapsed_time / processed_rows\n",
    "        estimated_time_remaining = (total_rows - processed_rows) * avg_time_per_row\n",
    "\n",
    "        print(f\"\\rProcessing: {processed_rows}/{total_rows} rows | \"\n",
    "              f\"Elapsed: {elapsed_time:.2f}s | \"\n",
    "              f\"Estimated time remaining: {estimated_time_remaining:.2f}s\", \n",
    "              end=\"\", flush=True)\n",
    "        return result\n",
    "\n",
    "    results = dataframe.apply(process_row, axis=1)\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(results)\n",
    "\n",
    "    # Filter out None values and flatten the list of lists to one single list of entities.\n",
    "    concept_list = [item for sublist in results if sublist is not None for item in sublist]\n",
    "    return concept_list\n",
    "\n",
    "def graph2Df(nodes_list) -> pd.DataFrame:\n",
    "    ## Remove all NaN entities\n",
    "    graph_dataframe = pd.DataFrame(nodes_list).replace(\" \", np.nan)\n",
    "    graph_dataframe = graph_dataframe.dropna(subset=[\"node_1\", \"node_2\"])\n",
    "    graph_dataframe[\"node_1\"] = graph_dataframe[\"node_1\"].apply(lambda x: x.lower())\n",
    "    graph_dataframe[\"node_2\"] = graph_dataframe[\"node_2\"].apply(lambda x: x.lower())\n",
    "\n",
    "    return graph_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = documents2Dataframe(pages)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 10/10 rows | Elapsed: 86.10s | Estimated time remaining: 0.00s\n",
      "Processing complete!\n",
      "(57, 5)\n"
     ]
    }
   ],
   "source": [
    "## To regenerate the graph with LLM, set this to True\n",
    "regenerate = True\n",
    "\n",
    "if regenerate:\n",
    "    concepts_list = df2Graph(df)\n",
    "    dfg1 = graph2Df(concepts_list)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    dfg1.to_csv(output_dir/\"graph.csv\", sep=\"|\", index=False)\n",
    "    df.to_csv(output_dir/\"chunks.csv\", sep=\"|\", index=False)\n",
    "else:\n",
    "    dfg1 = pd.read_csv(output_dir/\"graph.csv\", sep=\"|\")\n",
    "\n",
    "dfg1.replace(\"\", np.nan, inplace=True)\n",
    "dfg1.dropna(subset=[\"node_1\", \"node_2\", 'edge'], inplace=True)\n",
    "dfg1['count'] = 4 \n",
    "## Increasing the weight of the relation to 4. \n",
    "## We will assign the weight of 1 when later the contextual proximity will be calculated.  \n",
    "print(dfg1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>void</td>\n",
       "      <td>setmem64</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>3</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>void</td>\n",
       "      <td>uint64</td>\n",
       "      <td>a4f133cb4e464f7182319101f644fdd6,f0cc8ca42f654...</td>\n",
       "      <td>4</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>void</td>\n",
       "      <td>uint8</td>\n",
       "      <td>a4f133cb4e464f7182319101f644fdd6,a4f133cb4e464...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>void</td>\n",
       "      <td>uintn</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>void</td>\n",
       "      <td>value</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>3</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    node_1    node_2                                           chunk_id  \\\n",
       "472   void  setmem64  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "474   void    uint64  a4f133cb4e464f7182319101f644fdd6,f0cc8ca42f654...   \n",
       "475   void     uint8  a4f133cb4e464f7182319101f644fdd6,a4f133cb4e464...   \n",
       "476   void     uintn  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "477   void     value  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "\n",
       "     count                  edge  \n",
       "472      3  contextual proximity  \n",
       "474      4  contextual proximity  \n",
       "475      2  contextual proximity  \n",
       "476      2  contextual proximity  \n",
       "477      3  contextual proximity  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contextual_proximity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ## Melt the dataframe into a list of nodes\n",
    "    dfg_long = pd.melt(\n",
    "        df, id_vars=[\"chunk_id\"], value_vars=[\"node_1\", \"node_2\"], value_name=\"node\"\n",
    "    )\n",
    "    dfg_long.drop(columns=[\"variable\"], inplace=True)\n",
    "    # Self join with chunk id as the key will create a link between terms occuring in the same text chunk.\n",
    "    dfg_wide = pd.merge(dfg_long, dfg_long, on=\"chunk_id\", suffixes=(\"_1\", \"_2\"))\n",
    "    # drop self loops\n",
    "    self_loops_drop = dfg_wide[dfg_wide[\"node_1\"] == dfg_wide[\"node_2\"]].index\n",
    "    dfg2 = dfg_wide.drop(index=self_loops_drop).reset_index(drop=True)\n",
    "    ## Group and count edges.\n",
    "    dfg2 = (\n",
    "        dfg2.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": [\",\".join, \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    dfg2.columns = [\"node_1\", \"node_2\", \"chunk_id\", \"count\"]\n",
    "    dfg2.replace(\"\", np.nan, inplace=True)\n",
    "    dfg2.dropna(subset=[\"node_1\", \"node_2\"], inplace=True)\n",
    "    # Drop edges with 1 count\n",
    "    dfg2 = dfg2[dfg2[\"count\"] != 1]\n",
    "    dfg2[\"edge\"] = \"contextual proximity\"\n",
    "    return dfg2\n",
    "\n",
    "\n",
    "dfg2 = contextual_proximity(dfg1)\n",
    "dfg2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>edge</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buffer</td>\n",
       "      <td>length</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>related to,contextual proximity</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buffer</td>\n",
       "      <td>setmem64</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buffer</td>\n",
       "      <td>uint64</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buffer</td>\n",
       "      <td>uintn</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buffer</td>\n",
       "      <td>value</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>void</td>\n",
       "      <td>setmem64</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>void</td>\n",
       "      <td>uint64</td>\n",
       "      <td>a4f133cb4e464f7182319101f644fdd6,f0cc8ca42f654...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>void</td>\n",
       "      <td>uint8</td>\n",
       "      <td>a4f133cb4e464f7182319101f644fdd6,a4f133cb4e464...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>void</td>\n",
       "      <td>uintn</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>void</td>\n",
       "      <td>value</td>\n",
       "      <td>f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     node_1    node_2                                           chunk_id  \\\n",
       "0    buffer    length  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "1    buffer  setmem64  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "2    buffer    uint64  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "3    buffer     uintn  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "4    buffer     value  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "..      ...       ...                                                ...   \n",
       "251    void  setmem64  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "252    void    uint64  a4f133cb4e464f7182319101f644fdd6,f0cc8ca42f654...   \n",
       "253    void     uint8  a4f133cb4e464f7182319101f644fdd6,a4f133cb4e464...   \n",
       "254    void     uintn  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "255    void     value  f0cc8ca42f65409fb235ded2248c2b8f,f0cc8ca42f654...   \n",
       "\n",
       "                                edge  count  \n",
       "0    related to,contextual proximity     13  \n",
       "1               contextual proximity      9  \n",
       "2               contextual proximity      3  \n",
       "3               contextual proximity      6  \n",
       "4               contextual proximity      9  \n",
       "..                               ...    ...  \n",
       "251             contextual proximity      3  \n",
       "252             contextual proximity      4  \n",
       "253             contextual proximity      2  \n",
       "254             contextual proximity      2  \n",
       "255             contextual proximity      3  \n",
       "\n",
       "[256 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg = pd.concat([dfg1, dfg2], axis=0)\n",
    "dfg = (\n",
    "    dfg.groupby([\"node_1\", \"node_2\"])\n",
    "    .agg({\"chunk_id\": \",\".join, \"edge\": ','.join, 'count': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = pd.concat([dfg['node_1'], dfg['node_2']], axis=0).unique()\n",
    "nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "## Add nodes to the graph\n",
    "for node in nodes:\n",
    "    G.add_node(\n",
    "        str(node)\n",
    "    )\n",
    "\n",
    "## Add edges to the graph\n",
    "for index, row in dfg.iterrows():\n",
    "    G.add_edge(\n",
    "        str(row[\"node_1\"]),\n",
    "        str(row[\"node_2\"]),\n",
    "        title=row[\"edge\"],\n",
    "        weight=row['count']/4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Communities =  5\n",
      "[['buffer', 'buffer alignment requirement', 'efi_scsi_io_protocol', 'efi_status', 'length', 'scsiread16commandex', 'scsiwrite16commandex', 'setmem64', 'uint64', 'uintn', 'value', 'void'], ['cdb', 'commandpacket', 'databuffer', 'datalength', 'efi_scsi_op_length_ten', 'efi_scsi_op_read16', 'efi_scsi_op_write10', 'executescsicommand', 'hostadapterstatus', 'outdatabuffer', 'outtransferlength', 'scsiio', 'sectorsize', 'sensedata', 'sensedatalength', 'startlba', 'targetstatus', 'timeout', 'uint8'], ['context', 'efi_scsi_op_length_sixteen', 'efi_scsi_op_write16', 'event', 'selfevent', 'uint32'], ['operand', 'result', 'safeintntouint32', 'safeuintntointn', 'safeuintntouint32', 'status'], ['safeint64touintn', 'safeintnadd', 'safeintntouintn', 'safeuint64tointn', 'safeuintnadd', 'testsafeintnadd', 'testsafeuint64tointn']]\n"
     ]
    }
   ],
   "source": [
    "communities_generator = nx.community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "print(\"Number of Communities = \", len(communities))\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>color</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buffer</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buffer alignment requirement</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efi_scsi_io_protocol</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efi_status</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>length</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scsiread16commandex</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scsiwrite16commandex</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>setmem64</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>uint64</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>uintn</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>value</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>void</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cdb</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>commandpacket</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>databuffer</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>datalength</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>efi_scsi_op_length_ten</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>efi_scsi_op_read16</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>efi_scsi_op_write10</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>executescsicommand</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hostadapterstatus</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>outdatabuffer</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>outtransferlength</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>scsiio</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sectorsize</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sensedata</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sensedatalength</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>startlba</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>targetstatus</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>timeout</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>uint8</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>context</td>\n",
       "      <td>#57db94</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>efi_scsi_op_length_sixteen</td>\n",
       "      <td>#57db94</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>efi_scsi_op_write16</td>\n",
       "      <td>#57db94</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>event</td>\n",
       "      <td>#57db94</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>selfevent</td>\n",
       "      <td>#57db94</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>uint32</td>\n",
       "      <td>#57db94</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>operand</td>\n",
       "      <td>#c957db</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>result</td>\n",
       "      <td>#c957db</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>safeintntouint32</td>\n",
       "      <td>#c957db</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>safeuintntointn</td>\n",
       "      <td>#c957db</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>safeuintntouint32</td>\n",
       "      <td>#c957db</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>status</td>\n",
       "      <td>#c957db</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>safeint64touintn</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>safeintnadd</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>safeintntouintn</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>safeuint64tointn</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>safeuintnadd</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>testsafeintnadd</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>testsafeuint64tointn</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            node    color  group\n",
       "0                         buffer  #b9db57      1\n",
       "1   buffer alignment requirement  #b9db57      1\n",
       "2           efi_scsi_io_protocol  #b9db57      1\n",
       "3                     efi_status  #b9db57      1\n",
       "4                         length  #b9db57      1\n",
       "5            scsiread16commandex  #b9db57      1\n",
       "6           scsiwrite16commandex  #b9db57      1\n",
       "7                       setmem64  #b9db57      1\n",
       "8                         uint64  #b9db57      1\n",
       "9                          uintn  #b9db57      1\n",
       "10                         value  #b9db57      1\n",
       "11                          void  #b9db57      1\n",
       "12                           cdb  #db5f57      2\n",
       "13                 commandpacket  #db5f57      2\n",
       "14                    databuffer  #db5f57      2\n",
       "15                    datalength  #db5f57      2\n",
       "16        efi_scsi_op_length_ten  #db5f57      2\n",
       "17            efi_scsi_op_read16  #db5f57      2\n",
       "18           efi_scsi_op_write10  #db5f57      2\n",
       "19            executescsicommand  #db5f57      2\n",
       "20             hostadapterstatus  #db5f57      2\n",
       "21                 outdatabuffer  #db5f57      2\n",
       "22             outtransferlength  #db5f57      2\n",
       "23                        scsiio  #db5f57      2\n",
       "24                    sectorsize  #db5f57      2\n",
       "25                     sensedata  #db5f57      2\n",
       "26               sensedatalength  #db5f57      2\n",
       "27                      startlba  #db5f57      2\n",
       "28                  targetstatus  #db5f57      2\n",
       "29                       timeout  #db5f57      2\n",
       "30                         uint8  #db5f57      2\n",
       "31                       context  #57db94      3\n",
       "32    efi_scsi_op_length_sixteen  #57db94      3\n",
       "33           efi_scsi_op_write16  #57db94      3\n",
       "34                         event  #57db94      3\n",
       "35                     selfevent  #57db94      3\n",
       "36                        uint32  #57db94      3\n",
       "37                       operand  #c957db      4\n",
       "38                        result  #c957db      4\n",
       "39              safeintntouint32  #c957db      4\n",
       "40               safeuintntointn  #c957db      4\n",
       "41             safeuintntouint32  #c957db      4\n",
       "42                        status  #c957db      4\n",
       "43              safeint64touintn  #5784db      5\n",
       "44                   safeintnadd  #5784db      5\n",
       "45               safeintntouintn  #5784db      5\n",
       "46              safeuint64tointn  #5784db      5\n",
       "47                  safeuintnadd  #5784db      5\n",
       "48               testsafeintnadd  #5784db      5\n",
       "49          testsafeuint64tointn  #5784db      5"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "palette = \"hls\"\n",
    "\n",
    "## Now add these colors to communities and make another dataframe\n",
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    random.shuffle(p)\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"node\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "\n",
    "colors = colors2Community(communities)\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in colors.iterrows():\n",
    "    G.nodes[row['node']]['group'] = row['group']\n",
    "    G.nodes[row['node']]['color'] = row['color']\n",
    "    G.nodes[row['node']]['size'] = G.degree[row['node']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./docs/index.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "graph_output_directory = \"./docs/index.html\"\n",
    "\n",
    "net = Network(\n",
    "    notebook=False,\n",
    "    # bgcolor=\"#1a1a1a\",\n",
    "    cdn_resources=\"remote\",\n",
    "    height=\"900px\",\n",
    "    width=\"100%\",\n",
    "    select_menu=True,\n",
    "    # font_color=\"#cccccc\",\n",
    "    filter_menu=False,\n",
    ")\n",
    "\n",
    "net.from_nx(G)\n",
    "# net.repulsion(node_distance=150, spring_length=400)\n",
    "net.force_atlas_2based(central_gravity=0.015, gravity=-31)\n",
    "# net.barnes_hut(gravity=-18100, central_gravity=5.05, spring_length=380)\n",
    "net.show_buttons(filter_=[\"physics\"])\n",
    "\n",
    "net.show(graph_output_directory, notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
