{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"output2.txt\"\n",
    "output_dir = Path(f\"./output_dir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 100\n",
      "Cdb = AllocateZeroPool (EFI_SCSI_OP_LENGTH_SIXTEEN);\n",
      "  if (Cdb == NULL) {\n",
      "    Status = EFI_OUT_OF_RE\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(data_file, encoding='utf-8')\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap = 100,\n",
    "    length_function = len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "pages = splitter.split_documents(documents)\n",
    "pages = pages[10000:10100]\n",
    "print(f\"Number of pages: {len(pages)}\")\n",
    "print(pages[3].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "api_key = os.getenv('API_KEY')\n",
    "base_url = os.getenv('API_URL')\n",
    "max_output_tokens = 300\n",
    "streaming = False\n",
    "http_client = httpx.Client(verify=False)\n",
    "available_models = [\n",
    "    \"mixtral-8x7b-instruct-v01\", \n",
    "    \"gemma-7b-it\", \n",
    "    \"mistral-7b-instruct-v02\", \n",
    "    \"llama-2-70b-chat\", \n",
    "    \"phi-3-mini-128k-instruct\", \n",
    "    \"llama-3-8b-instruct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating all the utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from yachalk import chalk\n",
    "from langchain_openai import ChatOpenAI,OpenAI\n",
    "\n",
    "# Append the parent directory to the system path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Initialize the ChatOpenAI client\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    model=available_models[0],\n",
    "    http_client=http_client,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "def trim_incomplete_json(json_string):\n",
    "    # Find the last occurrence of '}]' or '},' in the string\n",
    "    last_complete = max(json_string.rfind('}]'), json_string.rfind('},'))\n",
    "    \n",
    "    if last_complete != -1:\n",
    "        # If found, trim the string to that point and add closing bracket if needed\n",
    "        trimmed = json_string[:last_complete+1]\n",
    "        if not trimmed.endswith(']'):\n",
    "            trimmed += ']'\n",
    "        return trimmed\n",
    "    else:\n",
    "        # If no complete object found, return empty list\n",
    "        return '[]'\n",
    "\n",
    "def extract_concepts(prompt: str, metadata: dict = {}) -> list:\n",
    "    SYS_PROMPT = (\n",
    "        \"Your task is to extract the key concepts (and non-personal entities) mentioned in the given context. \"\n",
    "        \"Extract only the most important and atomistic concepts, breaking them down into simpler concepts if needed. \"\n",
    "        \"Categorize the concepts into one of the following categories: \"\n",
    "        \"[import statement, concept, function definition, object-calling, document, class-definition, condition, misc].\\n\"\n",
    "        \"Format your output as a list of JSON objects in the following format:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"   {\\n\"\n",
    "        '       \"entity\": \"The Concept\",\\n'\n",
    "        '       \"importance\": \"The contextual importance of the concept on a scale of 1 to 5 (5 being the highest)\",\\n'\n",
    "        '       \"category\": \"The Type of Concept\"\\n'\n",
    "        \"   },\\n\"\n",
    "        \"   {...}\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    response = client.invoke(input=messages)\n",
    "    print(\"Extract Prompt \", response)\n",
    "    try:\n",
    "        result = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"\\n\\nWARNING ### Incomplete JSON detected. Attempting to trim...\")\n",
    "        trimmed_response = trim_incomplete_json(response)\n",
    "        print(trimmed_response+\"\\n#####################################################################################################\")\n",
    "        try:\n",
    "            result = json.loads(trimmed_response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"\\n\\nERROR ### Failed to parse even after trimming. Here is the buggy response: \", response, \"\\n\\n\")\n",
    "            return None\n",
    "\n",
    "    if result is not None:\n",
    "        result = [dict(item, **metadata) for item in result]\n",
    "\n",
    "    return result\n",
    "\n",
    "def graph_prompt(input_text: str, metadata: dict = {}) -> list:\n",
    "    SYS_PROMPT = (\n",
    "        \"You are a network graph maker who extracts terms and their relations from a given context. \"\n",
    "        \"You are provided with a context chunk (delimited by ```). Your task is to extract the ontology \"\n",
    "        \"of terms mentioned in the given context. These terms should represent the key concepts according to the context.\\n\"\n",
    "        \"Thought 1: While traversing through each sentence, think about the key terms mentioned in it.\\n\"\n",
    "        \"\\tTerms may include object creation, entity, class definition, import file, function signature, \\n\"\n",
    "        \"\\tcondition, parameters, documents, service, concept, etc.\\n\"\n",
    "        \"\\tTerms should be as atomistic as possible.\\n\\n\"\n",
    "        \"Thought 2: Think about how these terms can have one-on-one relations with other terms.\\n\"\n",
    "        \"\\tTerms mentioned in the same code or file are typically related to each other.\\n\"\n",
    "        \"\\tTerms can be related to many other terms.\\n\\n\"\n",
    "        \"Thought 3: Determine the relation between each related pair of terms.\\n\\n\"\n",
    "        \"Format your output as a list of JSON objects. Each element of the list contains a pair of terms do not provide an explanation, JUST THE JSON OUTPUT \"\n",
    "        \"and the relationship between them, as follows:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"   {\\n\"\n",
    "        '       \"node_1\": \"A concept from the extracted ontology\",\\n'\n",
    "        '       \"node_2\": \"A related concept from the extracted ontology\",\\n'\n",
    "        '       \"edge\": \"The relationship between node_1 and node_2 in one or two sentences\"\\n'\n",
    "        \"   },\\n\"\n",
    "        \"   {...}\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "\n",
    "    USER_PROMPT = f\"context: ```{input_text}``` \\n\\n output: \"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT}\n",
    "    ]\n",
    "\n",
    "    response = client.invoke(input=messages)\n",
    "    # print(\"Graph Prompt \", response)\n",
    "    try:\n",
    "        result = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        # print(\"\\n\\nWARNING ### Incomplete JSON detected. Attempting to trim...\")\n",
    "        trimmed_response = trim_incomplete_json(response)\n",
    "        # print(trimmed_response)\n",
    "        # print(\"################################################################################################################\")\n",
    "        try:\n",
    "            result = json.loads(trimmed_response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"\\n\\nERROR ### Failed to parse even after trimming. Here is the buggy response: \")\n",
    "            return None\n",
    "\n",
    "    if result is not None:\n",
    "        result = [dict(item, **metadata) for item in result]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe and graph manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def documents2Dataframe(documents) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for chunk in documents:\n",
    "        row = {\n",
    "            \"text\": chunk.page_content,\n",
    "            **chunk.metadata,\n",
    "            \"chunk_id\": uuid.uuid4().hex,\n",
    "        }\n",
    "        rows = rows + [row]\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df2ConceptsList(dataframe: pd.DataFrame) -> list:\n",
    "    # dataframe.reset_index(inplace=True)\n",
    "    results = dataframe.apply(\n",
    "        lambda row: extract_concepts(\n",
    "            row.text, {\"chunk_id\": row.chunk_id, \"type\": \"concept\"}\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    # invalid json results in NaN\n",
    "    results = results.dropna()\n",
    "    results = results.reset_index(drop=True)\n",
    "\n",
    "    ## Flatten the list of lists to one single list of entities.\n",
    "    concept_list = np.concatenate(results).ravel().tolist()\n",
    "    return concept_list\n",
    "\n",
    "\n",
    "def concepts2Df(concepts_list) -> pd.DataFrame:\n",
    "    ## Remove all NaN entities\n",
    "    concepts_dataframe = pd.DataFrame(concepts_list).replace(\" \", np.nan)\n",
    "    concepts_dataframe = concepts_dataframe.dropna(subset=[\"entity\"])\n",
    "    concepts_dataframe[\"entity\"] = concepts_dataframe[\"entity\"].apply(\n",
    "        lambda x: x.lower()\n",
    "    )\n",
    "\n",
    "    return concepts_dataframe\n",
    "\n",
    "\n",
    "def df2Graph(dataframe: pd.DataFrame, model=None) -> list:\n",
    "    total_rows = len(dataframe)\n",
    "    processed_rows = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    def process_row(row):\n",
    "        nonlocal processed_rows\n",
    "        result = graph_prompt(row.text, {\"chunk_id\": row.chunk_id})\n",
    "        processed_rows += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        avg_time_per_row = elapsed_time / processed_rows\n",
    "        estimated_time_remaining = (total_rows - processed_rows) * avg_time_per_row\n",
    "\n",
    "        print(f\"\\rProcessing: {processed_rows}/{total_rows} rows | \"\n",
    "              f\"Elapsed: {elapsed_time:.2f}s | \"\n",
    "              f\"Estimated time remaining: {estimated_time_remaining:.2f}s\", \n",
    "              end=\"\", flush=True)\n",
    "        return result\n",
    "\n",
    "    results = dataframe.apply(process_row, axis=1)\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(results)\n",
    "\n",
    "    # Filter out None values and flatten the list of lists to one single list of entities.\n",
    "    concept_list = [item for sublist in results if sublist is not None for item in sublist]\n",
    "    return concept_list\n",
    "\n",
    "def graph2Df(nodes_list) -> pd.DataFrame:\n",
    "    ## Remove all NaN entities\n",
    "    graph_dataframe = pd.DataFrame(nodes_list).replace(\" \", np.nan)\n",
    "    graph_dataframe = graph_dataframe.dropna(subset=[\"node_1\", \"node_2\"])\n",
    "    graph_dataframe[\"node_1\"] = graph_dataframe[\"node_1\"].apply(lambda x: x.lower())\n",
    "    graph_dataframe[\"node_2\"] = graph_dataframe[\"node_2\"].apply(lambda x: x.lower())\n",
    "\n",
    "    return graph_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = documents2Dataframe(pages)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 100/100 rows | Elapsed: 1048.12s | Estimated time remaining: 0.00s\n",
      "Processing complete!\n",
      "0     [{'node_1': 'Cdb', 'node_2': 'AllocateZeroPool...\n",
      "1     [{'node_1': 'SCSI IO protocol', 'node_2': 'Dat...\n",
      "2     [{'node_1': 'EFI_SCSI_IO_PROTOCOL', 'node_2': ...\n",
      "3     [{'node_1': 'Cdb', 'node_2': 'EFI_SCSI_OP_LENG...\n",
      "4     [{'node_1': 'DataBuffer', 'node_2': 'SenseData...\n",
      "                            ...                        \n",
      "95    [{'node_1': 'UINT32', 'node_2': 'PciSegmentAnd...\n",
      "96    [{'node_1': 'PciSegmentBitFieldWrite32', 'node...\n",
      "97    [{'node_1': '32-bit PCI configuration register...\n",
      "98    [{'node_1': 'PciSegmentBitFieldAndThenOr32', '...\n",
      "99    [{'node_1': 'StartAddress', 'node_2': 'Pci Seg...\n",
      "Length: 100, dtype: object\n",
      "(422, 5)\n"
     ]
    }
   ],
   "source": [
    "## To regenerate the graph with LLM, set this to True\n",
    "regenerate = True\n",
    "\n",
    "if regenerate:\n",
    "    concepts_list = df2Graph(df)\n",
    "    dfg1 = graph2Df(concepts_list)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    dfg1.to_csv(output_dir/\"graph.csv\", sep=\"|\", index=False)\n",
    "    df.to_csv(output_dir/\"chunks.csv\", sep=\"|\", index=False)\n",
    "else:\n",
    "    dfg1 = pd.read_csv(output_dir/\"graph.csv\", sep=\"|\")\n",
    "\n",
    "dfg1.replace(\"\", np.nan, inplace=True)\n",
    "dfg1.dropna(subset=[\"node_1\", \"node_2\", 'edge'], inplace=True)\n",
    "dfg1['count'] = 4 \n",
    "## Increasing the weight of the relation to 4. \n",
    "## We will assign the weight of 1 when later the contextual proximity will be calculated.  \n",
    "print(dfg1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connecting node with more contextual proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding count to the edges to design strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>writeunaligned64</td>\n",
       "      <td>cdb</td>\n",
       "      <td>0e16cd3dde644d9caffbc3a1e6abbd9e,0e16cd3dde644...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>writeunaligned64</td>\n",
       "      <td>context</td>\n",
       "      <td>0e16cd3dde644d9caffbc3a1e6abbd9e,0e16cd3dde644...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>written to the pci configuration register</td>\n",
       "      <td>16-bit pci configuration register</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>written to the pci configuration register</td>\n",
       "      <td>bitwise or</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>written to the pci configuration register</td>\n",
       "      <td>value</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>3</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         node_1  \\\n",
       "2216                           writeunaligned64   \n",
       "2218                           writeunaligned64   \n",
       "2223  written to the pci configuration register   \n",
       "2225  written to the pci configuration register   \n",
       "2227  written to the pci configuration register   \n",
       "\n",
       "                                 node_2  \\\n",
       "2216                                cdb   \n",
       "2218                            context   \n",
       "2223  16-bit pci configuration register   \n",
       "2225                         bitwise or   \n",
       "2227                              value   \n",
       "\n",
       "                                               chunk_id  count  \\\n",
       "2216  0e16cd3dde644d9caffbc3a1e6abbd9e,0e16cd3dde644...      2   \n",
       "2218  0e16cd3dde644d9caffbc3a1e6abbd9e,0e16cd3dde644...      2   \n",
       "2223  a035eafc81404751b58272763517e146,a035eafc81404...      2   \n",
       "2225  a035eafc81404751b58272763517e146,a035eafc81404...      2   \n",
       "2227  a035eafc81404751b58272763517e146,a035eafc81404...      3   \n",
       "\n",
       "                      edge  \n",
       "2216  contextual proximity  \n",
       "2218  contextual proximity  \n",
       "2223  contextual proximity  \n",
       "2225  contextual proximity  \n",
       "2227  contextual proximity  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contextual_proximity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ## Melt the dataframe into a list of nodes\n",
    "    dfg_long = pd.melt(\n",
    "        df, id_vars=[\"chunk_id\"], value_vars=[\"node_1\", \"node_2\"], value_name=\"node\"\n",
    "    )\n",
    "    \n",
    "    dfg_long.drop(columns=[\"variable\"], inplace=True)\n",
    "\n",
    "    \n",
    "    # Self join with chunk id as the key will create a link between terms occuring in the same text chunk.\n",
    "    dfg_wide = pd.merge(dfg_long, dfg_long, on=\"chunk_id\", suffixes=(\"_1\", \"_2\"))\n",
    "\n",
    "    # drop self loops\n",
    "    self_loops_drop = dfg_wide[dfg_wide[\"node_1\"] == dfg_wide[\"node_2\"]].index\n",
    "    dfg2 = dfg_wide.drop(index=self_loops_drop).reset_index(drop=True)\n",
    "\n",
    "    ## Group and count edges.\n",
    "    dfg2 = (\n",
    "        dfg2.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": [\",\".join, \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    dfg2.columns = [\"node_1\", \"node_2\", \"chunk_id\", \"count\"]\n",
    "    dfg2.replace(\"\", np.nan, inplace=True)\n",
    "    dfg2.dropna(subset=[\"node_1\", \"node_2\"], inplace=True)\n",
    "    # Drop edges with 1 count\n",
    "    dfg2 = dfg2[dfg2[\"count\"] != 1]\n",
    "    dfg2[\"edge\"] = \"contextual proximity\"\n",
    "    return dfg2\n",
    "\n",
    "\n",
    "dfg2 = contextual_proximity(dfg1)\n",
    "dfg2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>edge</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-bit</td>\n",
       "      <td>pci configuration register</td>\n",
       "      <td>440f7804fc9d4de0b7e4553a2affffa6,440f7804fc9d4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-bit pci configuration register</td>\n",
       "      <td>address</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>The former is specified by the latter,contextu...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-bit pci configuration register</td>\n",
       "      <td>bitwise or</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-bit pci configuration register</td>\n",
       "      <td>ordata</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-bit pci configuration register</td>\n",
       "      <td>value</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>writeunaligned64</td>\n",
       "      <td>cdb</td>\n",
       "      <td>0e16cd3dde644d9caffbc3a1e6abbd9e,0e16cd3dde644...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>writeunaligned64</td>\n",
       "      <td>context</td>\n",
       "      <td>0e16cd3dde644d9caffbc3a1e6abbd9e,0e16cd3dde644...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>written to the pci configuration register</td>\n",
       "      <td>16-bit pci configuration register</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>written to the pci configuration register</td>\n",
       "      <td>bitwise or</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>written to the pci configuration register</td>\n",
       "      <td>value</td>\n",
       "      <td>a035eafc81404751b58272763517e146,a035eafc81404...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1253 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         node_1  \\\n",
       "0                                        16-bit   \n",
       "1             16-bit pci configuration register   \n",
       "2             16-bit pci configuration register   \n",
       "3             16-bit pci configuration register   \n",
       "4             16-bit pci configuration register   \n",
       "...                                         ...   \n",
       "1248                           writeunaligned64   \n",
       "1249                           writeunaligned64   \n",
       "1250  written to the pci configuration register   \n",
       "1251  written to the pci configuration register   \n",
       "1252  written to the pci configuration register   \n",
       "\n",
       "                                 node_2  \\\n",
       "0            pci configuration register   \n",
       "1                               address   \n",
       "2                            bitwise or   \n",
       "3                                ordata   \n",
       "4                                 value   \n",
       "...                                 ...   \n",
       "1248                                cdb   \n",
       "1249                            context   \n",
       "1250  16-bit pci configuration register   \n",
       "1251                         bitwise or   \n",
       "1252                              value   \n",
       "\n",
       "                                               chunk_id  \\\n",
       "0     440f7804fc9d4de0b7e4553a2affffa6,440f7804fc9d4...   \n",
       "1     a035eafc81404751b58272763517e146,a035eafc81404...   \n",
       "2     a035eafc81404751b58272763517e146,a035eafc81404...   \n",
       "3     a035eafc81404751b58272763517e146,a035eafc81404...   \n",
       "4     a035eafc81404751b58272763517e146,a035eafc81404...   \n",
       "...                                                 ...   \n",
       "1248  0e16cd3dde644d9caffbc3a1e6abbd9e,0e16cd3dde644...   \n",
       "1249  0e16cd3dde644d9caffbc3a1e6abbd9e,0e16cd3dde644...   \n",
       "1250  a035eafc81404751b58272763517e146,a035eafc81404...   \n",
       "1251  a035eafc81404751b58272763517e146,a035eafc81404...   \n",
       "1252  a035eafc81404751b58272763517e146,a035eafc81404...   \n",
       "\n",
       "                                                   edge  count  \n",
       "0                                  contextual proximity      3  \n",
       "1     The former is specified by the latter,contextu...      6  \n",
       "2                                  contextual proximity      4  \n",
       "3                                  contextual proximity      2  \n",
       "4                                  contextual proximity      6  \n",
       "...                                                 ...    ...  \n",
       "1248                               contextual proximity      2  \n",
       "1249                               contextual proximity      2  \n",
       "1250                               contextual proximity      2  \n",
       "1251                               contextual proximity      2  \n",
       "1252                               contextual proximity      3  \n",
       "\n",
       "[1253 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg = pd.concat([dfg1, dfg2], axis=0)\n",
    "dfg = (\n",
    "    dfg.groupby([\"node_1\", \"node_2\"])\n",
    "    .agg({\"chunk_id\": \",\".join, \"edge\": ','.join, 'count': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = pd.concat([dfg['node_1'], dfg['node_2']], axis=0).unique()\n",
    "nodes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "## Add nodes to the graph\n",
    "for node in nodes:\n",
    "    G.add_node(\n",
    "        str(node)\n",
    "    )\n",
    "\n",
    "## Add edges to the graph\n",
    "for index, row in dfg.iterrows():\n",
    "    G.add_edge(\n",
    "        str(row[\"node_1\"]),\n",
    "        str(row[\"node_2\"]),\n",
    "        title=row[\"edge\"],\n",
    "        weight=row['count']/4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Communities =  14\n",
      "[['16-bit', '16-bit pci configuration register', '16-bit value', '32-bit pci configuration register', 'addend', 'address', 'anddata', 'arpdriverbindingstart', 'arpdriverbindingsupported', 'attributes', 'augend', 'bit field', 'bitwise and', 'bitwise or', 'buffer', 'bus', 'capsulecount', 'capsuleheaderarray', 'cast', 'char16', 'convertpointer()', 'debugdisposition', 'device', 'devreq.value', 'dxepcisegmentlibpcirootbridgeioreadworker', 'dxepcisegmentlibpcirootbridgeiowriteworker', 'efi_capsule_header', 'efi_device_path_protocol', 'efi_driver_binding_protocol', 'efi_error', 'efi_get_wakeup_time', 'efi_guid', 'efi_invalid_parameter', 'efi_no_mapping', 'efi_not_found', 'efi_set_time', 'efi_status', 'efi_success', 'efi_time', 'efi_unsupported', 'efi_usb_io_protocol', 'efiapi', 'eficonvertpointer', 'efiresetcold', 'enable', 'endbit', 'error status', 'function', 'functions', 'gettime()', 'int32', 'int64', 'int8', 'intn', 'length', 'maximumvariablestoragesize', 'minternalrt', 'minternalrt->getnextvariablename', 'minternalrt->getvariable', 'minuend', 'multiplicand', 'multiplier', 'non-negative', 'operand', 'ordata', 'parameter', 'parameters', 'pci configuration', 'pci configuration register', 'pci segment', 'pci segment, bus, device, function, register', 'pcisegmentand32', 'pcisegmentandthenor32', 'pcisegmentbitfieldandthenor32', 'pcisegmentbitfieldor16', 'pcisegmentbitfieldor32', 'pcisegmentbitfieldwrite32', 'pcisegmentlibsearchforrootbridge', 'pcisegmentor8', 'pcisegmentread32', 'pcisegmentwrite32', 'pointer', 'querycapsulecapabilities()', 'read result', 'register', 'resetstatus', 'resetsystem()', 'resettype', 'result', 'return', 'return_buffer_too_small', 'safeint16sub', 'safeint32sub', 'safeint32touint32', 'safeint64add', 'safeint64mult', 'safeint64tointn', 'safeint64touintn', 'safeint8add', 'safeint8touint64', 'safeintnadd', 'safeintnmult', 'safeintnsub', 'safeintntochar8', 'safeintntouint16', 'safeuint8mult', 'safeuintnmult', 'safeuintntouint32', 'scattergatherlist', 'service', 'setmem64', 'settime()', 'startaddress', 'startbit', 'subtrahend', 'testsafeint8touint8', 'time', 'type', 'uefi', 'uefi runtime service', 'uefi runtime service querycapsulecapabilities()', 'uefi runtime service queryvariableinfo', 'uint16', 'uint32', 'uint64', 'uint8', 'uintn', 'unit_test', 'unit_test_context', 'unit_test_function', 'unit_test_passed', 'unit_test_status', 'usb_types_definition', 'usbgetdescriptor', 'usbgetreportdescriptor', 'usbio->usbcontroltransfer', 'usbsetdescriptor', 'usbsetfeature', 'value', 'value to or', 'value written', 'variablename', 'variablenamesize', 'variables', 'vendorguid', 'wakeup alarm', 'written to the pci configuration register'], ['additionsubtractiontestsuite', 'addtestcase', 'allocatezeropool', 'alternate setting', 'alternatesetting', 'assert', 'assert_efi_error', 'callerevent', 'cdb', 'commandpacket', 'context', 'context->commandpacket', 'context->sensedatalength', 'conversiontestsuite', 'createunittestsuite', 'databuffer', 'datalength', 'duration', 'efi_out_of_resources', 'efi_scsi_io_protocol', 'efi_scsi_op_length_sixteen', 'efi_usb_get_report_request', 'efiusbdatain', 'framework', 'freepool', 'gbs->closeevent', 'gbs->createevent', 'gbs->handleprotocol', 'hostadapterstatus', 'int16', 'interface', 'interface index value', 'mefiexitbootservicesevent', 'mefivirtualnotifyevent', 'multiplicationtestsuite', 'null', 'pcdget32', 'pcdusbtransfertimeoutvalue', 'pointer to the status of the transfer', 'report interface', 'request', 'runalltestsuites', 'safeint16tochar8', 'scsi io protocol', 'scsiio', 'scsiread16commandex', 'scsiwrite16command', 'scsiwrite16commandex', 'sensedata', 'sensedatalength', 'status', 'targetstatus', 'test safeint32touint32', 'test safeint8touint8', 'test safeuint64toint64', 'test safeuint64touintn', 'testsafeint32touint32', 'testsafeint32touintn', 'testsafeuint64touintn', 'testsafeuintntoint32', 'testsafeuintntouint16', 'timeout', 'uefitestmain', 'usb control transfer', 'usb control transfer function', 'usb i/o protocol', 'usb i/o protocol instance', 'usb set configuration request', 'usb_desc_type_hid', 'usb_hid_class_get_req_type', 'usb_req_get_descriptor', 'usbcontroltransfer', 'usbgetidlerequest', 'usbgetreportrequest', 'usbio', 'void', 'writeunaligned64'], ['allocatepool', 'mpcirootbridgedata'], ['arp service context data', 'arp_instance_data', 'arp_service_data', 'arpcomponentname', 'arpdriverbinding', 'arpservice', 'arpservice->mnpconfigdata', 'childhandle', 'childrennumber', 'configured', 'controller handle', 'controllerhandle', 'destroychild', 'efi_handle', 'efi_service_binding_protocol', 'enableunicastreceive', 'gefimanagednetworkservicebindingprotocolguid', 'imagehandle', 'indestroy', 'instance', 'list', 'mnpchildhandle', 'mnpconfigdata', 'mnpservice', 'protocoltypefilter', 'this'], ['devreq.index', 'target'], ['devreq.request', 'usb_req_clear_feature'], ['driver lib module globals', 'efi_event', 'global variable', 'non ipf processor types', 'pointer values', 'uefi runtime library', 'virtual mapping'], ['endpoint', 'endpoint address'], ['handlecount', 'mnumberofpcirootbridges'], ['mpcirootbridgedata[index].pcirootbridgeio', 'pcirootbridgeio'], ['pcisegmentregisterforruntimeaccess', 'return_out_of_resources', 'return_status', 'return_unsupported'], ['report identifier', 'reportid'], ['report length', 'reportlength'], ['report type', 'reporttype']]\n"
     ]
    }
   ],
   "source": [
    "communities_generator = nx.community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "print(\"Number of Communities = \", len(communities))\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette = \"hls\"\n",
    "\n",
    "## Now add these colors to communities and make another dataframe\n",
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    random.shuffle(p)\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"node\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "\n",
    "colors = colors2Community(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in colors.iterrows():\n",
    "    G.nodes[row['node']]['group'] = row['group']\n",
    "    G.nodes[row['node']]['color'] = row['color']\n",
    "    G.nodes[row['node']]['size'] = G.degree[row['node']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./docs/index.html\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "\n",
    "k_value = 2  # Adjust this value to change node spacing\n",
    "pos = nx.spring_layout(G, k=k_value, iterations=50)\n",
    "\n",
    "\n",
    "net = Network(notebook=False, cdn_resources=\"remote\", height=\"1200px\", width=\"1200px\")\n",
    "\n",
    "\n",
    "for node, (x, y) in pos.items():\n",
    "    net.add_node(\n",
    "        node,\n",
    "        x=x * 200, \n",
    "        y=y * 200,\n",
    "        physics=True,  \n",
    "        **G.nodes[node] \n",
    "    )\n",
    "\n",
    "# Add edges to the Pyvis network\n",
    "for source, target, edge_attrs in G.edges(data=True):\n",
    "    edge_data = edge_attrs.copy()\n",
    "    edge_data['value'] = edge_data['weight']\n",
    "    net.add_edge(\n",
    "        source,\n",
    "        target,\n",
    "        **edge_data\n",
    "    )\n",
    "\n",
    "# Disable physics in Pyvis to maintain the NetworkX layout\n",
    "net.toggle_physics(True)\n",
    "\n",
    "# Save the network\n",
    "net.show(\"./docs/index.html\", notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
