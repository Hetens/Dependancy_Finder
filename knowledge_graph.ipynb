{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"output2.txt\"\n",
    "output_dir = Path(f\"./output_dir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12257\n",
      "/**\n",
      " * Tes\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(data_file, encoding='utf-8')\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap = 100,\n",
    "    length_function = len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "pages = splitter.split_documents(documents)\n",
    "print(len(pages))\n",
    "pages = pages[10000:10300]  \n",
    "print(pages[3].page_content[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "api_key = os.getenv('API_KEY')\n",
    "base_url = os.getenv('API_URL')\n",
    "max_output_tokens = 300\n",
    "streaming = False\n",
    "http_client = httpx.Client(verify=False)\n",
    "available_models = [\n",
    "    \"mixtral-8x7b-instruct-v01\", \n",
    "    \"gemma-7b-it\", \n",
    "    \"mistral-7b-instruct-v02\", \n",
    "    \"llama-2-70b-chat\", \n",
    "    \"phi-3-mini-128k-instruct\", \n",
    "    \"llama-3-8b-instruct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from yachalk import chalk\n",
    "from langchain_openai import ChatOpenAI,OpenAI\n",
    "llm = OpenAI(\n",
    "    base_url=base_url,\n",
    "    model=available_models[0],\n",
    "    http_client=http_client,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating all the utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Append the parent directory to the system path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Initialize the ChatOpenAI client\n",
    "\n",
    "def trim_incomplete_json(json_string):\n",
    "    # Find the last occurrence of '}]' or '},' in the string\n",
    "    last_complete = max(json_string.rfind('}]'), json_string.rfind('},'))\n",
    "    \n",
    "    if last_complete != -1:\n",
    "        # If found, trim the string to that point and add closing bracket if needed\n",
    "        trimmed = json_string[:last_complete+1]\n",
    "        if not trimmed.endswith(']'):\n",
    "            trimmed += ']'\n",
    "        return trimmed\n",
    "    else:\n",
    "        # If no complete object found, return empty list\n",
    "        return '[]'\n",
    "\n",
    "def extract_concepts(prompt: str, metadata: dict = {}) -> list:\n",
    "    SYS_PROMPT = (\n",
    "        \"Your task is to extract the key concepts (and non-personal entities) mentioned in the given context. \"\n",
    "        \"Extract only the most important and atomistic concepts, breaking them down into simpler concepts if needed. \"\n",
    "        \"Categorize the concepts into one of the following categories: \"\n",
    "        \"[import statement, concept, function definition, object-calling, document, class-definition, condition, misc].\\n\"\n",
    "        \"Format your output as a list of JSON objects in the following format:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"   {\\n\"\n",
    "        '       \"entity\": \"The Concept\",\\n'\n",
    "        '       \"importance\": \"The contextual importance of the concept on a scale of 1 to 5 (5 being the highest)\",\\n'\n",
    "        '       \"category\": \"The Type of Concept\"\\n'\n",
    "        \"   },\\n\"\n",
    "        \"   {...}\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(input=messages)\n",
    "    print(\"Extract Prompt \", response)\n",
    "    try:\n",
    "        result = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"\\n\\nWARNING ### Incomplete JSON detected. Attempting to trim...\")\n",
    "        trimmed_response = trim_incomplete_json(response)\n",
    "        print(trimmed_response+\"\\n#####################################################################################################\")\n",
    "        try:\n",
    "            result = json.loads(trimmed_response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"\\n\\nERROR ### Failed to parse even after trimming. Here is the buggy response: \", response, \"\\n\\n\")\n",
    "            return None\n",
    "\n",
    "    if result is not None:\n",
    "        result = [dict(item, **metadata) for item in result]\n",
    "\n",
    "    return result\n",
    "\n",
    "def graph_prompt(input_text: str, metadata: dict = {}) -> list:\n",
    "    SYS_PROMPT = (\n",
    "        \"You are a network graph maker who extracts terms and their relations from a given context. \"\n",
    "        \"You are provided with a context chunk (delimited by ```). Your task is to extract the ontology \"\n",
    "        \"of terms mentioned in the given context. These terms should represent the key concepts according to the context.\\n\"\n",
    "        \"Thought 1: While traversing through each sentence, think about whether Data is being passed to it\\n\"\n",
    "        \"\\tTerms may include object creation, entity, class definition, import file, function signature, \\n\"\n",
    "        \"\\tcondition, parameters, documents, service, concept, etc.\\n\"\n",
    "        \"\\tTerms should be as concise as possible.\\n\\n\"\n",
    "        \"Thought 2: Think about how these terms can have one-on-one relations with other terms.\\n\"\n",
    "        \"\\tTerms mentioned in the same code or file are typically related to each other.\\n\"\n",
    "        \"\\tTerms can be related to many other terms.\\n\\n\"\n",
    "        \"Thought 3: Determine the relation between each related pair of terms.\\n\\n\"\n",
    "        \"Format your output as a list of JSON objects. Each element of the list contains a pair of terms do not provide an explanation, JUST THE JSON OUTPUT \"\n",
    "        \"and the relationship between them, as follows:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"   {\\n\"\n",
    "        '       \"node_1\": \"A concept from the extracted ontology\",\\n'\n",
    "        '       \"node_2\": \"A related concept from the extracted ontology\",\\n'\n",
    "        '       \"edge\": \"The relationship between node_1 and node_2 in one or two sentences\"\\n'\n",
    "        \"   },\\n\"\n",
    "        \"   {...}\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "\n",
    "    USER_PROMPT = f\"context: ```{input_text}``` \\n\\n output: \"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT}\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(input=messages)\n",
    "    # print(\"Graph Prompt \", response)\n",
    "    try:\n",
    "        result = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        # print(\"\\n\\nWARNING ### Incomplete JSON detected. Attempting to trim...\")\n",
    "        trimmed_response = trim_incomplete_json(response)\n",
    "        # print(trimmed_response)\n",
    "        # print(\"################################################################################################################\")\n",
    "        try:\n",
    "            result = json.loads(trimmed_response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"\\n\\nERROR ### Failed to parse even after trimming. Here is the buggy response: \")\n",
    "            return None\n",
    "\n",
    "    if result is not None:\n",
    "        result = [dict(item, **metadata) for item in result]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe and graph manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def documents2Dataframe(documents) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for chunk in documents:\n",
    "        row = {\n",
    "            \"text\": chunk.page_content,\n",
    "            **chunk.metadata,\n",
    "            \"chunk_id\": uuid.uuid4().hex,\n",
    "        }\n",
    "        rows = rows + [row]\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df2ConceptsList(dataframe: pd.DataFrame) -> list:\n",
    "    # dataframe.reset_index(inplace=True)\n",
    "    results = dataframe.apply(\n",
    "        lambda row: extract_concepts(\n",
    "            row.text, {\"chunk_id\": row.chunk_id, \"type\": \"concept\"}\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    # invalid json results in NaN\n",
    "    results = results.dropna()\n",
    "    results = results.reset_index(drop=True)\n",
    "\n",
    "    ## Flatten the list of lists to one single list of entities.\n",
    "    concept_list = np.concatenate(results).ravel().tolist()\n",
    "    return concept_list\n",
    "\n",
    "\n",
    "def concepts2Df(concepts_list) -> pd.DataFrame:\n",
    "    ## Remove all NaN entities\n",
    "    concepts_dataframe = pd.DataFrame(concepts_list).replace(\" \", np.nan)\n",
    "    concepts_dataframe = concepts_dataframe.dropna(subset=[\"entity\"])\n",
    "    concepts_dataframe[\"entity\"] = concepts_dataframe[\"entity\"].apply(\n",
    "        lambda x: x.lower()\n",
    "    )\n",
    "\n",
    "    return concepts_dataframe\n",
    "\n",
    "\n",
    "def df2Graph(dataframe: pd.DataFrame, model=None) -> list:\n",
    "    total_rows = len(dataframe)\n",
    "    processed_rows = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    def process_row(row):\n",
    "        nonlocal processed_rows\n",
    "        result = graph_prompt(row.text, {\"chunk_id\": row.chunk_id})\n",
    "        processed_rows += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        avg_time_per_row = elapsed_time / processed_rows\n",
    "        estimated_time_remaining = (total_rows - processed_rows) * avg_time_per_row\n",
    "\n",
    "        print(f\"\\rProcessing: {processed_rows}/{total_rows} rows | \"\n",
    "              f\"Elapsed: {elapsed_time:.2f}s | \"\n",
    "              f\"Estimated time remaining: {estimated_time_remaining:.2f}s\", \n",
    "              end=\"\", flush=True)\n",
    "        return result\n",
    "\n",
    "    results = dataframe.apply(process_row, axis=1)\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(results)\n",
    "\n",
    "    # Filter out None values and flatten the list of lists to one single list of entities.\n",
    "    concept_list = [item for sublist in results if sublist is not None for item in sublist]\n",
    "    return concept_list\n",
    "\n",
    "def graph2Df(nodes_list) -> pd.DataFrame:\n",
    "    ## Remove all NaN entities\n",
    "    graph_dataframe = pd.DataFrame(nodes_list).replace(\" \", np.nan)\n",
    "    graph_dataframe = graph_dataframe.dropna(subset=[\"node_1\", \"node_2\"])\n",
    "    graph_dataframe[\"node_1\"] = graph_dataframe[\"node_1\"].apply(lambda x: x.lower())\n",
    "    graph_dataframe[\"node_2\"] = graph_dataframe[\"node_2\"].apply(lambda x: x.lower())\n",
    "\n",
    "    return graph_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = documents2Dataframe(pages)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 31/300 rows | Elapsed: 565.73s | Estimated time remaining: 4909.09s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 41/300 rows | Elapsed: 736.18s | Estimated time remaining: 4650.53s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 44/300 rows | Elapsed: 805.86s | Estimated time remaining: 4688.66s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 102/300 rows | Elapsed: 1839.07s | Estimated time remaining: 3569.96s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 108/300 rows | Elapsed: 1955.50s | Estimated time remaining: 3476.45s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 133/300 rows | Elapsed: 2352.10s | Estimated time remaining: 2953.39s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 163/300 rows | Elapsed: 2853.13s | Estimated time remaining: 2398.03s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 164/300 rows | Elapsed: 2871.46s | Estimated time remaining: 2381.21s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 179/300 rows | Elapsed: 3135.65s | Estimated time remaining: 2119.63s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 245/300 rows | Elapsed: 4160.62s | Estimated time remaining: 934.02ss\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 249/300 rows | Elapsed: 4231.81s | Estimated time remaining: 866.76s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 261/300 rows | Elapsed: 4373.49s | Estimated time remaining: 653.51s\n",
      "\n",
      "ERROR ### Failed to parse even after trimming. Here is the buggy response: \n",
      "Processing: 300/300 rows | Elapsed: 5055.73s | Estimated time remaining: 0.00sss\n",
      "Processing complete!\n",
      "0      [{'node_1': 'spdm_test_context', 'node_2': 'sp...\n",
      "1      [{'node_1': 'libspdm_context', 'node_2': 'spdm...\n",
      "2      [{'node_1': 'libspdm_return_t', 'node_2': 'lib...\n",
      "3      [{'node_1': 'libspdm_test_responder_key_update...\n",
      "4      [{'node_1': 'libspdm_compute_secret_update', '...\n",
      "                             ...                        \n",
      "295    [{'node_1': 'SupportedAttributes', 'node_2': '...\n",
      "296    [{'node_1': 'OPAL_SESSION', 'node_2': 'OPAL_DI...\n",
      "297    [{'node_1': 'TPM_TAG_RQU_COMMAND', 'node_2': '...\n",
      "298    [{'node_1': 'HashInstanceLibSha256', 'node_2':...\n",
      "299    [{'node_1': 'API', 'node_2': 'TPM Operation Re...\n",
      "Length: 300, dtype: object\n",
      "(1149, 5)\n"
     ]
    }
   ],
   "source": [
    "## To regenerate the graph with LLM, set this to True\n",
    "regenerate = True\n",
    "\n",
    "if regenerate:\n",
    "    concepts_list = df2Graph(df)\n",
    "    dfg1 = graph2Df(concepts_list)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    dfg1.to_csv(output_dir/\"graph.csv\", sep=\"|\", index=False)\n",
    "    df.to_csv(output_dir/\"chunks.csv\", sep=\"|\", index=False)\n",
    "else:\n",
    "    dfg1 = pd.read_csv(output_dir/\"graph.csv\", sep=\"|\")\n",
    "\n",
    "dfg1.replace(\"\", np.nan, inplace=True)\n",
    "dfg1.dropna(subset=[\"node_1\", \"node_2\", 'edge'], inplace=True)\n",
    "dfg1['count'] = 4 \n",
    "## Increasing the weight of the relation to 4. \n",
    "## We will assign the weight of 1 when later the contextual proximity will be calculated.  \n",
    "print(dfg1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connecting node with more contextual proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding count to the edges to design strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>void</td>\n",
       "      <td>verifytimebasedpayload</td>\n",
       "      <td>96448546d897479e89f7743755655ece,96448546d8974...</td>\n",
       "      <td>4</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5897</th>\n",
       "      <td>void **state</td>\n",
       "      <td>libspdm_context_t</td>\n",
       "      <td>15db715acae549fbaba3d8821adb4099,15db715acae54...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>void **state</td>\n",
       "      <td>libspdm_test_context_t</td>\n",
       "      <td>904ffa7eddec45fa9bfe1bd7b22700ad,15db715acae54...</td>\n",
       "      <td>3</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>void **state</td>\n",
       "      <td>libspdm_test_responder_finish_case10</td>\n",
       "      <td>904ffa7eddec45fa9bfe1bd7b22700ad,904ffa7eddec4...</td>\n",
       "      <td>3</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>void *data</td>\n",
       "      <td>verifytimebasedpayloadandupdate</td>\n",
       "      <td>a2b41c75af5341e5b0c712bb28ae1c95,a2b41c75af534...</td>\n",
       "      <td>4</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            node_1                                node_2  \\\n",
       "5896          void                verifytimebasedpayload   \n",
       "5897  void **state                     libspdm_context_t   \n",
       "5899  void **state                libspdm_test_context_t   \n",
       "5900  void **state  libspdm_test_responder_finish_case10   \n",
       "5905    void *data       verifytimebasedpayloadandupdate   \n",
       "\n",
       "                                               chunk_id  count  \\\n",
       "5896  96448546d897479e89f7743755655ece,96448546d8974...      4   \n",
       "5897  15db715acae549fbaba3d8821adb4099,15db715acae54...      2   \n",
       "5899  904ffa7eddec45fa9bfe1bd7b22700ad,15db715acae54...      3   \n",
       "5900  904ffa7eddec45fa9bfe1bd7b22700ad,904ffa7eddec4...      3   \n",
       "5905  a2b41c75af5341e5b0c712bb28ae1c95,a2b41c75af534...      4   \n",
       "\n",
       "                      edge  \n",
       "5896  contextual proximity  \n",
       "5897  contextual proximity  \n",
       "5899  contextual proximity  \n",
       "5900  contextual proximity  \n",
       "5905  contextual proximity  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contextual_proximity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ## Melt the dataframe into a list of nodes\n",
    "    dfg_long = pd.melt(\n",
    "        df, id_vars=[\"chunk_id\"], value_vars=[\"node_1\", \"node_2\"], value_name=\"node\"\n",
    "    )\n",
    "    \n",
    "    dfg_long.drop(columns=[\"variable\"], inplace=True)\n",
    "\n",
    "    \n",
    "    # Self join with chunk id as the key will create a link between terms occuring in the same text chunk.\n",
    "    dfg_wide = pd.merge(dfg_long, dfg_long, on=\"chunk_id\", suffixes=(\"_1\", \"_2\"))\n",
    "\n",
    "    # drop self loops\n",
    "    self_loops_drop = dfg_wide[dfg_wide[\"node_1\"] == dfg_wide[\"node_2\"]].index\n",
    "    dfg2 = dfg_wide.drop(index=self_loops_drop).reset_index(drop=True)\n",
    "\n",
    "    ## Group and count edges.\n",
    "    dfg2 = (\n",
    "        dfg2.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": [\",\".join, \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    dfg2.columns = [\"node_1\", \"node_2\", \"chunk_id\", \"count\"]\n",
    "    dfg2.replace(\"\", np.nan, inplace=True)\n",
    "    dfg2.dropna(subset=[\"node_1\", \"node_2\"], inplace=True)\n",
    "    # Drop edges with 1 count\n",
    "    dfg2 = dfg2[dfg2[\"count\"] != 1]\n",
    "    dfg2[\"edge\"] = \"contextual proximity\"\n",
    "    return dfg2\n",
    "\n",
    "\n",
    "dfg2 = contextual_proximity(dfg1)\n",
    "dfg2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>edge</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*shadigest</td>\n",
       "      <td>uint8</td>\n",
       "      <td>5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*shadigest</td>\n",
       "      <td>uintn</td>\n",
       "      <td>5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*signercert</td>\n",
       "      <td>uint8</td>\n",
       "      <td>5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*signercert</td>\n",
       "      <td>uintn</td>\n",
       "      <td>5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*tbscert</td>\n",
       "      <td>uint8</td>\n",
       "      <td>5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>void</td>\n",
       "      <td>verifytimebasedpayload</td>\n",
       "      <td>96448546d897479e89f7743755655ece,96448546d8974...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>void **state</td>\n",
       "      <td>libspdm_context_t</td>\n",
       "      <td>15db715acae549fbaba3d8821adb4099,15db715acae54...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>void **state</td>\n",
       "      <td>libspdm_test_context_t</td>\n",
       "      <td>904ffa7eddec45fa9bfe1bd7b22700ad,15db715acae54...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>void **state</td>\n",
       "      <td>libspdm_test_responder_finish_case10</td>\n",
       "      <td>904ffa7eddec45fa9bfe1bd7b22700ad,904ffa7eddec4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>void *data</td>\n",
       "      <td>verifytimebasedpayloadandupdate</td>\n",
       "      <td>a2b41c75af5341e5b0c712bb28ae1c95,a2b41c75af534...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3321 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            node_1                                node_2  \\\n",
       "0       *shadigest                                 uint8   \n",
       "1       *shadigest                                 uintn   \n",
       "2      *signercert                                 uint8   \n",
       "3      *signercert                                 uintn   \n",
       "4         *tbscert                                 uint8   \n",
       "...            ...                                   ...   \n",
       "3316          void                verifytimebasedpayload   \n",
       "3317  void **state                     libspdm_context_t   \n",
       "3318  void **state                libspdm_test_context_t   \n",
       "3319  void **state  libspdm_test_responder_finish_case10   \n",
       "3320    void *data       verifytimebasedpayloadandupdate   \n",
       "\n",
       "                                               chunk_id                  edge  \\\n",
       "0     5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...  contextual proximity   \n",
       "1     5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...  contextual proximity   \n",
       "2     5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...  contextual proximity   \n",
       "3     5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...  contextual proximity   \n",
       "4     5a5c49109d3e40bba1b720c96851b5c1,5a5c49109d3e4...  contextual proximity   \n",
       "...                                                 ...                   ...   \n",
       "3316  96448546d897479e89f7743755655ece,96448546d8974...  contextual proximity   \n",
       "3317  15db715acae549fbaba3d8821adb4099,15db715acae54...  contextual proximity   \n",
       "3318  904ffa7eddec45fa9bfe1bd7b22700ad,15db715acae54...  contextual proximity   \n",
       "3319  904ffa7eddec45fa9bfe1bd7b22700ad,904ffa7eddec4...  contextual proximity   \n",
       "3320  a2b41c75af5341e5b0c712bb28ae1c95,a2b41c75af534...  contextual proximity   \n",
       "\n",
       "      count  \n",
       "0         5  \n",
       "1         2  \n",
       "2         5  \n",
       "3         2  \n",
       "4         5  \n",
       "...     ...  \n",
       "3316      4  \n",
       "3317      2  \n",
       "3318      3  \n",
       "3319      3  \n",
       "3320      4  \n",
       "\n",
       "[3321 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg = pd.concat([dfg1, dfg2], axis=0)\n",
    "dfg = (\n",
    "    dfg.groupby([\"node_1\", \"node_2\"])\n",
    "    .agg({\"chunk_id\": \",\".join, \"edge\": ','.join, 'count': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(860,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = pd.concat([dfg['node_1'], dfg['node_2']], axis=0).unique()\n",
    "nodes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "## Add nodes to the graph\n",
    "for node in nodes:\n",
    "    G.add_node(\n",
    "        str(node)\n",
    "    )\n",
    "\n",
    "## Add edges to the graph\n",
    "for index, row in dfg.iterrows():\n",
    "    G.add_edge(\n",
    "        str(row[\"node_1\"]),\n",
    "        str(row[\"node_2\"]),\n",
    "        title=row[\"edge\"],\n",
    "        weight=row['count']/4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Communities =  39\n",
      "[['(efi_signature_data *)((uint8 *)dbxlist + siglistheadersize)', 'certhash'], ['*shadigest', '*signercert', '*tbscert', '*toplevelcert', 'acpi method', 'aead_cipher_suite', 'algorithm', 'allocatepool', 'allocatezeropool', 'allocationsize', 'api', 'app_message', 'app_message_size', 'application_secret', 'asb', 'assert_int_equal', 'assert_non_null', 'ata_pass_thru_protocol', 'atacommandblock', 'atapassthru', 'atapassthru->passthru', 'atapassthrucommandpacket', 'atapassthrupassthru', 'atapassthruprotocol', 'attributes', 'authdata', 'authdatasize', 'authenticated data', 'authentication pass', 'authenticationstatus', 'authserviceinternalfindvariable', 'authserviceinternalupdatevariablewithtimestamp', 'authsession', 'authstate', 'authvariableinfo.attributes', 'authvartype', 'authvartypekek', 'authvartypepk', 'base', 'base_asym_algo', 'base_hash_algo', 'block i/o device', 'blockcount', 'blockio', 'bool', 'boolean', 'buffer', 'bufsize', 'bus', 'busy', 'calculateprivauthvarsignchainshadigest', 'capability', 'capability.flags', 'capabilityflags', 'case_id', 'cautionkey', 'ccmeasurementprotocol', 'ccprotocol', 'cert', 'cert_buffer', 'certcount', 'certdata', 'certdatabuffer', 'certdataptr', 'certdatasize', 'certificate cleaning process', 'certlist', 'certnumber', 'certptr', 'certssizeindb', 'char16', 'char16 *', 'char16 *variablename', 'char8', 'char_carriage_return', 'check_expected', 'checkdata', 'checksignaturelistformat', 'checkstoredhashfv', 'configformentry', 'confirmtext', 'connection_info', 'connection_info.capability.flags', 'connection_state', 'context', 'convertdevicepathtotext', 'copymem', 'createdevicemeasurementcontext', 'createpcidevicemeasurementcontext', 'createtimebasedpayload', 'createunittestsuite', 'ctxsize', 'data', 'data32', 'datasize', 'datatohash', 'datatohashlen', 'db entries', 'dbname', 'dbxdata', 'debug', 'debug_code_begin', 'debug_code_end', 'debug_info', 'debuglib', 'decode_secured_message_context', 'default_primary_table_header_size_of_partition_entry', 'deletedb', 'deletedbtshoulddelete', 'deletedbxshoulddelete', 'deleteplatformkey', 'deletesecurebootvariables', 'deletesecurebootvariablesshouldcheckprotection', 'deletesecurebootvariablesshouldproceedwithnotfound', 'deletevariable', 'device', 'devicehandle', 'deviceid', 'deviceio', 'devinfolength', 'digestlist', 'disablepkprotection', 'dodeviceauthentication', 'dodevicecertificate', 'dummydata', 'dxeimageverificationhandler', 'dxeimageverificationlib', 'dxeimageverificationlibimageread', 'dxetpmmeasureboothandler', 'edkii_variable_policy_protocol', 'efi_access_denied', 'efi_ata_pass_thru_mode', 'efi_ata_pass_thru_protocol', 'efi_block_io_protocol', 'efi_cc_measurement_protocol', 'efi_dbx_default_variable_name', 'efi_device_path_protocol', 'efi_error', 'efi_error (status)', 'efi_event', 'efi_firmware_image_authentication', 'efi_guid', 'efi_guid *vendorguid', 'efi_handle', 'efi_hash2_protocol', 'efi_hash_get_context_size', 'efi_hash_info', 'efi_hash_init', 'efi_hii_config_access_protocol', 'efi_image_execution_auth_sig_failed', 'efi_image_section_header', 'efi_image_security_database', 'efi_image_security_database1', 'efi_image_security_database2', 'efi_invalid_parameter', 'efi_not_ready', 'efi_out_of_resources', 'efi_partition_table_header', 'efi_pei_services', 'efi_physical_address', 'efi_physical_presence', 'efi_physical_presence_flags', 'efi_platform_key_name', 'efi_secure_boot_mode_name', 'efi_security_violation', 'efi_service_binding_protocol', 'efi_setup_mode_name', 'efi_signature_data', 'efi_signature_list', 'efi_status', 'efi_string', 'efi_tcg2_physical_presence', 'efi_tcg2_protocol', 'efi_tcg_protocol', 'efi_time', 'efi_variable_non_volatile', 'efi_variable_runtime_access', 'efi_variable_time_based_authenticated_write_access', 'efi_vendor_keys_variable_name', 'efiapi', 'eficreateprotocolnotifyevent', 'efiresetshutdown', 'efisig', 'enabled', 'encode_secured_message_context', 'enrollfromdefault', 'enrollkekfromdefault', 'enrollpkfromdefault', 'entropy', 'ev_efi_spdm_firmware_blob', 'eventdata2', 'eventlog', 'eventlogptr', 'eventlogsize', 'eventptr', 'eventsize', 'eventtype', 'executephysicalpresence', 'expect_memory', 'expect_value', 'extendmeasurement', 'f12', 'file', 'filebuffer', 'filesize', 'findhashalginfo', 'firmware volume', 'firmwaremanagement', 'fixedmedia', 'flags', 'fmp capsule', 'fmp capsule image', 'fmpauthenticatedhandlerpkcs7', 'fmpauthenticatedhandlerrsa2048sha256', 'fmpauthenticationlib', 'fmpauthenticationlibrsa2048sha256.c', 'framework', 'freepool', 'function', 'fvaddress', 'fvbprotocol', 'fvindex', 'fvinfo', 'fvnumber', 'fvreportpei.h', 'gbs', 'gbs->handleprotocol', 'gefiblockioprotocolguid', 'geficcmeasurementprotocolguid', 'gefifirmwarevolumeblockprotocolguid', 'gefiglobalvariableguid', 'gefiimagesecuritydatabaseguid', 'gefitcg2protocolguid', 'gefitcgprotocolguid', 'getbootmodehob', 'getcertsfromdb', 'getcontextsize', 'getdevicemeasurementcontextsize', 'gethashinfo', 'gethashsize', 'gethddpasswordsecuritystatus', 'getrandomnumber128', 'getsetupmode () api', 'getvariable', 'getvariable2', 'getvariable3', 'gpthandle', 'grt', 'grt->resetsystem', 'hash', 'hash2_service_data', 'hash2servicedata', 'hash_alg_info', 'hash_handle', 'hash_size', 'hashalg', 'hashalgid', 'hashalgoid', 'hashalgorithm', 'hashandextend', 'hashbase', 'hashcompleteandextend', 'hashctx', 'hashdata', 'hashfinal', 'hashflag', 'hashguid', 'hashhandle', 'hashinfo', 'hashinit', 'hashinstancelibsha256', 'hashinterface', 'hashinterfacehob', 'hashinterfacehob->hashinterfacecount', 'hashlibbasecryptorouterdxeconstructor', 'hashlogextendevent', 'hashmask', 'hashpeimagebytype', 'hashsize', 'hashstart', 'hashupdate', 'havevalidtpmrequest', 'hdd_password_dxe_private_data', 'hdd_password_request_variable', 'hdd_password_variable', 'hddpasswordconfigforminit', 'hddpasswordnotificationevent', 'hddpasswordsecuritystatus', 'hmac_size', 'identifier', 'imageaddress', 'imagecontext', 'imagehandle', 'imagesize', 'imageverificationhandler', 'in ata_identify_data *identifydata', 'in out hdd_password_config *ifrdata', 'index', 'init', 'initialize_secured_message_context', 'initunittestframework', 'internaldumpdata', 'isdeleteauthvariable', 'isdeviceauthbootenabled', 'isforbiddenbydbx', 'istimezero', 'isvalidsignaturebytimestamp', 'key', 'key.unicodechar', 'last_key_update_request', 'lastpprequest', 'latest_session_id', 'length', 'libspdm_compute_secret_update', 'libspdm_connection_state', 'libspdm_context', 'libspdm_context_t', 'libspdm_decode_secured_message', 'libspdm_encode_secured_message', 'libspdm_finish_request4.signature', 'libspdm_finish_response_t', 'libspdm_get_hash_size', 'libspdm_get_req_asym_signature_size', 'libspdm_get_response_finish', 'libspdm_get_response_set_certificate', 'libspdm_get_response_version', 'libspdm_hash_all', 'libspdm_register_vendor_get_id_callback_func', 'libspdm_requester_data_sign', 'libspdm_reset_message_a', 'libspdm_response_state', 'libspdm_return_t', 'libspdm_set_certificate_request', 'libspdm_status_success', 'libspdm_test_context_t', 'libspdm_test_context_version', 'libspdm_test_responder_finish_case10', 'libspdm_test_responder_finish_case11', 'libspdm_test_responder_finish_case13', 'libspdm_test_responder_finish_case14', 'libspdm_test_responder_finish_case15', 'libspdm_test_responder_finish_case17', 'libspdm_test_responder_finish_case18', 'libspdm_test_responder_finish_case21', 'libspdm_test_responder_finish_case22', 'libspdm_test_responder_finish_case3', 'libspdm_test_responder_finish_case4', 'libspdm_test_responder_key_update_case19', 'libspdm_test_responder_key_update_case21', 'libspdm_test_responder_key_update_case24', 'libspdm_test_responder_receive_send_rsp_case1', 'libspdm_test_responder_receive_send_rsp_case3', 'libspdm_test_responder_set_cetificate_rsp_case7', 'libspdm_test_responder_vendor_cmds_case1', 'libspdm_test_responder_vendor_cmds_err_case1', 'libspdm_test_secured_message_encode_case5', 'libspdm_test_secured_message_encode_case6', 'libspdm_use_hash_algo', 'libspdm_use_req_asym_algo', 'lifetimelock', 'local_context', 'local_context.capability.flags', 'localauthsession', 'm_libspdm_get_version_request1', 'm_libspdm_get_version_request1_size', 'm_libspdm_set_certificate_request', 'm_libspdm_set_certificate_request_size', 'm_libspdm_use_hash_algo', 'm_libspdm_use_req_asym_algo', 'm_secured_message_context', 'mask', 'max_hdd_password_retry_count', 'max_uint32', 'mcerttype', 'measurebootpolicy', 'measurebootprotocols', 'measurebootprotocols->ccprotocol', 'measurebootprotocols->tcg2protocol', 'measuregpttable', 'measurementblock', 'measurementrecordlength', 'measurementsblocksize', 'measurevariable', 'media', 'message_size', 'mhashalginfo', 'mhashinfo', 'mhashinterface', 'mhashtypestr', 'mimagebase', 'mimagedigest', 'mimagedigestsize', 'mimagesize', 'mmeasuredauthoritylist', 'mockgetvariable', 'mocksetvariable', 'mostrecentrequest', 'mplatformmode', 'muserphysicalpresence', 'mut_auth_requested', 'mvendorkeystate', 'needphysicallypresent', 'newcert', 'newcertdb', 'newcertdbsize', 'newcertlist', 'newvariable', 'null', 'numberofpartition', 'numberofpartitionentries', 'os runtime phase', 'parameter', 'passthru', 'password', 'payload', 'payloadinfo', 'payloadptr', 'payloadsize', 'pcdgetbool', 'pcdtcg2hashalgorithmbitmap', 'pcduserphysicalpresence', 'pcrindex', 'pe/coff image', 'pecoffloadergetimageinfo', 'peiservices', 'physical presence', 'physical presence variable', 'physical_presence_enable_activate', 'physicalpresencegetstringbyid', 'pk', 'platformauth', 'pointer', 'pointertorawdata', 'port', 'portmultiplierport', 'ppdata', 'ppiflags', 'ppiflags->ppflags', 'pprequest', 'ppresponse', 'primaryheader', 'private', 'processhddpasswordrequest', 'processing', 'processvariable', 'processvarwithkek', 'protocol', 'ptr', 'registration', 'removablemedia', 'req_asym_signature_size', 'request', 'requestconfirmed', 'response', 'response_size', 'response_state', 'restorelockbox', 'retrycount', 'return', 'return_status', 'return_success', 'revocationtime', 'rootcert', 'rootcertsize', 's3initdeviceslength', 'saltvalue', 'sectionheader', 'securebootcreatedatafrominput', 'securebootcreatedatafrominput () api', 'securebootfetchdata', 'securebootinitdbxdefault', 'securebootinitpkdefault', 'securebootvariablelib', 'securebootvarmisctests', 'secured_message_0', 'secured_message_context', 'secured_message_size', 'secured_message_version', 'securitystate', 'securitystatus', 'seed', 'sequence_number_endian', 'session_id', 'session_info', 'session_state', 'session_type', 'setdefaultsecurebootvariables', 'sethddpassword', 'setsecurebootmode', 'setsecurebootvariablesshouldstopfailkek', 'setsecurebootvariablesshouldstopwhensecure', 'setsecurebootvariablestodefault', 'setup_mode', 'setvariable', 'sha1ctx', 'sha1final', 'sha1getcontextsize', 'sha1update', 'sha384ctx', 'sha384final', 'sha384update', 'shadigest', 'signaturedata', 'signercerts', 'signercertsize', 'signingtime', 'size', 'size_t', 'sizeof', 'sizeof (dummy)', 'sizeof(spdm_set_certificate_response_t)', 'sizeofpartitionentry', 'sizeofrawdata', 'sm3ctx', 'sm3getcontextsize', 'spdm_context', 'spdm_context->connection_info', 'spdm_context->connection_info.capability.flags', 'spdm_context->connection_info.connection_state', 'spdm_context->connection_info.version', 'spdm_context->local_context', 'spdm_context->spdm_context', 'spdm_context_info', 'spdm_finish_response_t', 'spdm_get_capabilities_response_flags_chunk_cap', 'spdm_get_capabilities_response_flags_handshake_in_the_clear_cap', 'spdm_get_capabilities_response_flags_meas_cap', 'spdm_message_version_11', 'spdm_response', 'spdm_set_certificate_request_t', 'spdm_set_certificate_response_t', 'spdm_test_context', 'spdm_test_context->case_id', 'spdm_test_context->spdm_context', 'spdm_unit_test.h', 'spdm_version', 'spdmcontext', 'spdmdatabasehashalgo', 'spdmdatacapabilityflags', 'spdmdataspdmversion', 'spdmdevicecontext', 'spdmdeviceinfo', 'spdmdevicetype', 'spdmgetmeasurement', 'spdmioprotocol', 'spdmioprotocolguid', 'spdmreturn', 'state', 'status', 'step 3', 'storedhashfvppi', 'string_token', 'supported', 'systemtable', 'tcg2_physical_presence', 'tcg2_physical_presence_variable', 'tcg2executependingtpmrequest', 'tcg2havevalidtpmrequest', 'tcg2physicalpresencegetstringbyid', 'tcg2physicalpresencelibgetuserconfirmationstatusfunction', 'tcg2physicalpresencelibreturnoperationresponsetoosfunction', 'tcg2physicalpresencelibsubmitrequesttopreosfunction', 'tcg2physicalpresencelibsubmitrequesttopreosfunctionex', 'tcg2protocol', 'tcg2readuserkey', 'tcg2userconfirm', 'tcg_device_security_event_data_device_auth_state_fail_invalid', 'tcg_device_security_event_data_device_auth_state_no_auth', 'tcg_device_security_event_data_device_auth_state_no_binding', 'tcg_device_security_event_data_device_auth_state_success', 'tcg_device_security_event_data_header2', 'tcg_device_security_event_data_signature_2', 'tcg_device_security_event_data_version_2', 'tcg_physical_presence_vendor_specific_operation', 'tcg_pp_operation_response_success', 'tcg_supported_security_protocols', 'tcg_vendor_lib_flag_reset_track', 'tcgeventsize', 'tcgmeasuregpttable', 'tcgmeasurepeimage', 'tcgphysicalpresencelibneeduserconfirm', 'tcgphysicalpresencelibprocessrequest', 'tcgppdata', 'tcgppvendorlibgetuserconfirmationstatusfunction', 'tcgppvendorlibsubmitrequesttopreosfunction', 'tcgprotocol', 'tempvariable', 'test case', 'testsanitizeefipartitiontableheader', 'this', 'time', 'tmpstr1', 'toplevelcertsize', 'tpm operation', 'tpm operation response', 'tpm physical presence operation request', 'tpm12measureandlogdata', 'tpm2b_auth', 'tpm2changeeps', 'tpm2clear', 'tpm2hashmask', 'tpm_alg_id', 'tpm_cap_flag', 'tpm_cmd_get_capability', 'tpm_head_str', 'tpm_ord_getcapability', 'tpm_permanent_flags', 'tpm_physical_presence', 'tpm_rqu_command_hdr', 'tpm_rsp_command_hdr', 'tpm_stclear_flags', 'tpm_tag_rqu_command', 'tpmi_dh_pcr', 'tpmmeasureandlogdata', 'tpmpermanentflags', 'tpmpp', 'tpmppcommand', 'tpmppcommandparameter', 'tpmresponse', 'tpmrqu', 'tpmrsp', 'tpmsanitizeprimaryheaderallocationsize', 'true or false', 'uefi', 'uint16', 'uint32', 'uint32_t', 'uint8', 'uint8_t', 'uintn', 'unicode', 'unicodesprint', 'unit test', 'unit test suite', 'unit_test_context', 'unit_test_error_test_failed', 'unit_test_framework_handle', 'unit_test_passed', 'unit_test_status', 'unit_test_suite_handle', 'unittestingentry', 'unsupported', 'untrusted input', 'userphysicalpresent', 'validation', 'validslotid', 'value', 'variable', 'variable_record', 'variablename', 'variablesize', 'varname', 'vendorguid', 'vendorkeyismodified', 'verifytimebasedpayload', 'verifytimebasedpayloadandupdate', 'version', 'void', 'void **state', 'void *data'], ['addtestcase', 'securebootvardeletetests', 'securebootvarenrolltests', 'testcase'], ['allocateruntimepool', 'imageexeinfoentry', 'imageexeinfotable', 'newimageexeinfotable', 'numberofimages'], ['assert_int_equal(0x0022, *(uint16_t*)&m_secured_message[4 + partial_seq_num_size])', 'encode_secured_message_context.application_secret.request_data_sequence_number', 'partial_seq_num_size', 'sequence number'], ['authentication fail', 'return_security_violation'], ['authenticodeverify', 'verifystatus'], ['authserviceinternalupdatevariable', 'efi_secure_boot_enable_name', 'gefisecurebootenabledisableguid', 'securebootenable'], ['authvarlibcontextin', 'authvarlibcontextout', 'mauthvarlibcontextin', 'mauthvarlibcontextout', 'mhashsha256ctx', 'mhashsha384ctx'], ['base_cr', 'base_list_for_each', 'entry', 'hdd_password_config_form_entry', 'link', 'mhddpasswordconfigformlist'], ['bool status', 'file_data', 'file_size', 'libspdm_test_spdm_verify_cert_dicetcdinfo', 'libspdm_verify_cert_dicetcbinfo'], ['buf', 'comidextension', 'compacket', 'createstruct', 'curpacket', 'cursubpacket', 'error_check', 'hostsessionid', 'locking sp', 'methodstatus', 'newpin', 'null_check', 'opal_disk_support_attribute', 'opal_locking_sp_admin1_authority', 'opal_session', 'opal_uid_locking_sp', 'opalcreateretrievegloballockingrangeactivekey', 'opalperformmethod', 'opalssc1', 'opalssc2', 'opalssclite', 'parsestruct', 'pyritessc', 'pyritesscv2', 'revertsp', 'security provider id', 'session', 'sp1', 'supported protocol list', 'supportedattributes', 'tcg_create_struct', 'tcg_parse_struct', 'tcg_result', 'tcgaddendname', 'tcgaddendofdata', 'tcgaddstartlist', 'tcgcreatesetcpin', 'tcgcreatestartsession', 'tcgendmethodset', 'tcggetmethodstatus', 'tcggetnextbytesequence', 'tcggetnextendname', 'tcggetnextstartlist', 'tcggetnextstartname', 'tcggetnextuint32', 'tcginittcgcreatestruct', 'tcgresultfailure', 'tcgresultsuccess', 'tcgstartcompacket', 'tcgstartmethodcall', 'tcgstartpacket', 'tcgstartsubpacket', 'tmpparsestruct', 'trylimit'], ['buffer containing a tcg_com_packet', 'tcg_com_packet', 'tcgstorageopallib', 'trusted_send_status'], ['buffersize', 'transferlength512'], ['certblockrsa2048sha256', 'efi guided section header', 'efi_cert_block_rsa_2048_sha256', 'efi_guid_defined_section', 'efi_guid_defined_section2', 'efi_guided_section_processing_required', 'guid_defined_section', 'guid_defined_section2', 'if condition', 'inputsection', 'outputbuffersize', 'rsa 2048 sha 256 guided section header', 'rsa_2048_sha_256_section2_header', 'rsa_2048_sha_256_section_header', 'section2_size', 'section_size'], ['certhashcount', 'dbxlist->signaturelistsize - siglistheadersize) / dbxlist->signaturesize'], ['cmocka_unit_test', 'libspdm_responder_finish_test_main', 'libspdm_responder_key_exchange_test_main', 'libspdm_responder_key_update_test_main', 'libspdm_responder_key_update_tests', 'libspdm_responder_psk_exchange_test_main', 'libspdm_responder_psk_finish_test_main', 'libspdm_setup_test_context', 'libspdm_test_responder_finish_case1', 'libspdm_unit_test_group_setup', 'spdm_responder_finish_tests', 'unit test cases'], ['configuration', 'hiiisconfighdrmatch', 'mhddpasswordvendorguid', 'mhddpasswordvendorstoragename'], ['contentinfo', 'contenttype', 'digestalgorithmidentifier', 'digestalgorithmidentifiers', 'hash algorithm', 'signeddata'], ['cryptostatus', 'rsasetkey', 'sha256final', 'sha256init', 'sha256update'], ['data buffer to be hashed', 'event log length in bytes', 'event type', 'measurement event log', 'pcr index'], ['db', 'dbt', 'dbx', 'kek', 'secureboot keys', 'securebootpayload'], ['devicepathnode', 'devicepathtype', 'handle', 'media_device_path', 'origdevicepathnode'], ['dxetpmmeasurebootlibimageread', 'measuredfvhob', 'mfilebuffer', 'tpmimagesize'], ['efi_image_nt_headers32', 'hdr.pe32'], ['efi_image_nt_signature', 'hdr.pe32->signature'], ['efi_storage_security_command_protocol', 'opaltrustedsend'], ['efi_tcg2_event', 'efi_tcg2_event_header'], ['extractguidedsectionregisterhandlers', 'geficerttypersa2048sha256guid', 'rsa2048sha256guidedsectiongetinfo', 'rsa2048sha256guidedsectionhandler'], ['halfuidauthorityobjectref', 'halfuidbooleanace', 'tcgaddbytesequence'], ['libspdm_enable_capability_encap_cap', 'libspdm_responder_encapsulated_response_test_main', 'return_value'], ['libspdm_requester_lib.h', 'libspdm_responder_lib.h'], ['libspdm_responder_version_test_context', 'libspdm_test_responder_version_case1', 'libspdm_test_responder_version_case2'], ['libspdm_vendor_request_test', 'spdm_message_header_t'], ['mediaid', 'sscp'], ['no authentication handler associated with certtype', 'return_unsupported'], ['return_invalid_parameter', 'the image is in an invalid format'], ['securityprotocol', 'spspecific'], ['siglistheadersize', 'sizeof (efi_signature_list) + dbxlist->signatureheadersize']]\n"
     ]
    }
   ],
   "source": [
    "communities_generator = nx.community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "print(\"Number of Communities = \", len(communities))\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette = \"hls\"\n",
    "\n",
    "## Now add these colors to communities and make another dataframe\n",
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    random.shuffle(p)\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"node\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "\n",
    "colors = colors2Community(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in colors.iterrows():\n",
    "    G.nodes[row['node']]['group'] = row['group']\n",
    "    G.nodes[row['node']]['color'] = row['color']\n",
    "    G.nodes[row['node']]['size'] = G.degree[row['node']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./docs/index.html\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "\n",
    "k_value = 2  # Adjust this value to change node spacing\n",
    "pos = nx.spring_layout(G, k=k_value, iterations=50)\n",
    "\n",
    "\n",
    "net = Network(notebook=False, cdn_resources=\"remote\", height=\"1200px\", width=\"1200px\")\n",
    "\n",
    "\n",
    "for node, (x, y) in pos.items():\n",
    "    net.add_node(\n",
    "        node,\n",
    "        x=x * 200, \n",
    "        y=y * 200,\n",
    "        physics=True,  \n",
    "        **G.nodes[node] \n",
    "    )\n",
    "\n",
    "# Add edges to the Pyvis network\n",
    "for source, target, edge_attrs in G.edges(data=True):\n",
    "    edge_data = edge_attrs.copy()\n",
    "    edge_data['value'] = edge_data['weight']\n",
    "    net.add_edge(\n",
    "        source,\n",
    "        target,\n",
    "        **edge_data\n",
    "    )\n",
    "\n",
    "# Disable physics in Pyvis to maintain the NetworkX layout\n",
    "net.toggle_physics(True)\n",
    "\n",
    "# Save the network\n",
    "net.show(\"./docs/index.html\", notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
