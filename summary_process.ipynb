{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_numbers</th>\n",
       "      <th>path</th>\n",
       "      <th>main_function_inferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-91</td>\n",
       "      <td>vram\\EmulatorPkg\\Library\\PlatformBmLib\\Platfor...</td>\n",
       "      <td>Here is a one-line summary of the code snippet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-67</td>\n",
       "      <td>vram\\EmulatorPkg\\ThunkPpiToProtocolPei\\ThunkPp...</td>\n",
       "      <td>Here is a one-line summary of the code snippet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-10</td>\n",
       "      <td>vram\\EmulatorPkg\\Library\\SecPpiListLib\\PpiList...</td>\n",
       "      <td>Here is a one-line summary of the code snippet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-137</td>\n",
       "      <td>vram\\EmulatorPkg\\Unix\\Host\\BerkeleyPacketFilter.c</td>\n",
       "      <td>Here is a one-line summary of the main functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138-290</td>\n",
       "      <td>vram\\EmulatorPkg\\Unix\\Host\\BerkeleyPacketFilter.c</td>\n",
       "      <td>Here is a one-line summary of the main functio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  line_numbers                                               path  \\\n",
       "0         1-91  vram\\EmulatorPkg\\Library\\PlatformBmLib\\Platfor...   \n",
       "1         1-67  vram\\EmulatorPkg\\ThunkPpiToProtocolPei\\ThunkPp...   \n",
       "2         1-10  vram\\EmulatorPkg\\Library\\SecPpiListLib\\PpiList...   \n",
       "3        1-137  vram\\EmulatorPkg\\Unix\\Host\\BerkeleyPacketFilter.c   \n",
       "4      138-290  vram\\EmulatorPkg\\Unix\\Host\\BerkeleyPacketFilter.c   \n",
       "\n",
       "                              main_function_inferred  \n",
       "0  Here is a one-line summary of the code snippet...  \n",
       "1  Here is a one-line summary of the code snippet...  \n",
       "2  Here is a one-line summary of the code snippet...  \n",
       "3  Here is a one-line summary of the main functio...  \n",
       "4  Here is a one-line summary of the main functio...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_csv('./output_dir/summarized_output.csv')\n",
    "data.head()\n",
    "# Lets pass this as a chunk to LLM and Identify the file and lines that would be useful for system testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest_indices =[]\n",
    "for index, row in data.iterrows():\n",
    "    if 'UnitTestFrameworkPkg' in row['path']:\n",
    "        unittest_indices.append(index)\n",
    "\n",
    "data.drop(unittest_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "data.to_csv('./output_dir/summarized_output_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make a chunk of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path=\"./output_dir/summarized_output_filtered.csv\", encoding=\"utf-8\", csv_args={\n",
    "            'delimiter': ','})\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12357"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hetansh_Shah\\AppData\\Local\\Temp\\ipykernel_16576\\703933014.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\Hetansh_Shah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm, trange\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model = \"all-MiniLM-L6-v2\"\n",
    "embedding = HuggingFaceEmbeddings(model_name =embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "vector_store = FAISS.from_documents(data, embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a601ff732b4a9cb2986a99850b556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving data:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2add5e141d5f4a3e93c8ae9115a6dd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting labels:   0%|          | 0/12357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70859cace54b404da9c4126086c6840c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing t-SNE:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dfd003155b4b63b6c2583384cd9342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clustering:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a58db1dc8044c8e910393bc14405195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding communities:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def girvan_newman_clustering(embeddings, k):\n",
    "    # Create a graph from the embeddings\n",
    "    with tqdm(total=3, desc=\"Clustering\") as pbar:\n",
    "        distances = pdist(embeddings)\n",
    "        dist_matrix = squareform(distances)\n",
    "        G = nx.from_numpy_array(dist_matrix)\n",
    "        pbar.update(1)\n",
    "\n",
    "        # Perform Girvan-Newman clustering\n",
    "        comp = nx.community.girvan_newman(G)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Get the first k communities\n",
    "        for _ in tqdm(range(k-1), desc=\"Finding communities\", leave=False):\n",
    "            communities = next(comp)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    return communities\n",
    "\n",
    "def plot_faiss_vector_store_clustered(vector_store, n_components=2, perplexity=30, n_iter=1000, n_clusters=5):\n",
    "    # Retrieve embeddings and documents\n",
    "    with tqdm(total=2, desc=\"Retrieving data\") as pbar:\n",
    "        embeddings = vector_store.index.reconstruct_n(0, vector_store.index.ntotal)\n",
    "        pbar.update(1)\n",
    "        docs = list(vector_store.docstore._dict.values())\n",
    "        pbar.update(1)\n",
    "    \n",
    "    # Extract short text snippets for labels\n",
    "    texts = [doc.page_content.split('\\n')[1][-10:] for doc in tqdm(docs, desc=\"Extracting labels\")]\n",
    "    \n",
    "    # Perform t-SNE\n",
    "    with tqdm(total=1, desc=\"Performing t-SNE\") as pbar:\n",
    "        tsne = TSNE(n_components=n_components, perplexity=perplexity, max_iter=n_iter, random_state=42)\n",
    "        embeddings_2d = tsne.fit_transform(embeddings)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    # Perform Girvan-Newman clustering\n",
    "    communities = girvan_newman_clustering(embeddings_2d, n_clusters)\n",
    "    \n",
    "    # Assign colors to communities\n",
    "    color_map = plt.cm.get_cmap('viridis')\n",
    "    colors = [color_map(i / n_clusters) for i in range(n_clusters)]\n",
    "    \n",
    "    # Plot\n",
    "    with tqdm(total=1, desc=\"Plotting\") as pbar:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i, community in enumerate(communities):\n",
    "            community = list(community)\n",
    "            plt.scatter(embeddings_2d[community, 0], embeddings_2d[community, 1], \n",
    "                        c=[colors[i]], alpha=0.7, label=f'Cluster {i+1}')\n",
    "        \n",
    "        # Add labels for a few random points\n",
    "        n_labels = min(10, len(texts))\n",
    "        indices = np.random.choice(len(texts), n_labels, replace=False)\n",
    "        for i in indices:\n",
    "            plt.annotate(texts[i], (embeddings_2d[i, 0], embeddings_2d[i, 1]), fontsize=8)\n",
    "        \n",
    "        plt.title(f\"t-SNE visualization of FAISS vector store with Girvan-Newman clustering\\n(perplexity={perplexity}, n_iter={n_iter}, n_clusters={n_clusters})\")\n",
    "        plt.xlabel(\"t-SNE feature 0\")\n",
    "        plt.ylabel(\"t-SNE feature 1\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        pbar.update(1)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "plot_faiss_vector_store_clustered(vector_store, n_clusters=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = [\n",
    "    \"mixtral-8x7b-instruct-v01\", \n",
    "    \"gemma-7b-it\", \n",
    "    \"mistral-7b-instruct-v02\", \n",
    "    \"llama-2-70b-chat\", \n",
    "    \"phi-3-mini-128k-instruct\", \n",
    "    \"llama-3-8b-instruct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "base_url = os.getenv('API_URL')\n",
    "http_client = httpx.Client(verify=False)\n",
    "model_selected = available_models[5]\n",
    "global_texts = None\n",
    "langchain_llm = ChatOpenAI(\n",
    "    base_url=base_url,\n",
    "    model=model_selected,\n",
    "    http_client=http_client,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "os.environ[\"GROQ_API_KEY\"] =str(os.getenv(\"GROQ_API_KEY\"))\n",
    "# Your existing setup code\n",
    "http_client = httpx.Client(verify=False)\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0.3,\n",
    "    http_client=http_client,\n",
    "    max_tokens=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running The chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"Your task is to provide me with line-numbers and paths of sections that would be useful for system-level testing you can decide what type of system-level testing you can perform avoid unittesting at all costs.\n",
    "            The output should be in a list of JSON format with keys as:\n",
    "            1) coverage: this represents what all file_names would be covered in the test.\n",
    "            2) path: the path of the all important files.\n",
    "            3) line-numbers: the line number range that I should visit to utilize to conduct these tests.\n",
    "            Note: DO NOT USE THE FILES WHICH HAVE 'UnitTest' OR 'Sample' AS A PART OF THEIR NAME.\n",
    "            Give me as many JSON outputs as you can to cover the whole content.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I'll provide you with some suggestions for system-level testing. Since the context only provides information about the MtrrLib library, I'll focus on that. Here are some JSON outputs that might be useful for system-level testing:\n",
      "\n",
      "**Test 1: MTRR Configuration**\n",
      "```json\n",
      "{\n",
      "  \"coverage\": [\"MtrrLib\"],\n",
      "  \"path\": [\"vram/UefiCpuPkg/Library/MtrrLib/\"],\n",
      "  \"line-numbers\": [\"10-20\"]\n",
      "}\n",
      "```\n",
      "This test would cover the MtrrLib library's configuration and setup, focusing on the lines that initialize and set up the MTRR settings.\n",
      "\n",
      "**Test 2: Memory Attribute Management**\n",
      "```json\n",
      "{\n",
      "  \"coverage\": [\"MtrrLib\"],\n",
      "  \"path\": [\"vram/UefiCpuPkg/Library/MtrrLib/\"],\n",
      "  \"line-numbers\": [\"30-40\"]\n",
      "}\n",
      "```\n",
      "This test would cover the MtrrLib library's memory attribute management, focusing on the lines that set and get memory attributes in the MTRR settings.\n",
      "\n",
      "**Test 3: MTRR Register Access**\n",
      "```json\n",
      "{\n",
      "  \"coverage\": [\"MtrrLib\"],\n",
      "  \"path\": [\"vram/UefiCpuPkg/Library/MtrrLib/\"],\n",
      "  \"line-numbers\": [\"50-60\"]\n",
      "}\n",
      "```\n",
      "This test would cover the MtrrLib library's access to the MTRR registers, focusing on the lines that read and write to the registers.\n",
      "\n",
      "Please note that these suggestions are based on the limited context provided and might not be exhaustive. Additionally, since the context doesn't provide information about other files or libraries, these tests might not cover the entire system.\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=vector_store.as_retriever()\n",
    "            )\n",
    "result = qa_chain.invoke(query)            \n",
    "print(result['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
